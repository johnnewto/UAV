[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UAV",
    "section": "",
    "text": "documentation is available at UAV docs"
  },
  {
    "objectID": "index.html#guide-to-developing-with-uav",
    "href": "index.html#guide-to-developing-with-uav",
    "title": "UAV",
    "section": "Guide to developing with UAV",
    "text": "Guide to developing with UAV"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "UAV",
    "section": "Install",
    "text": "Install\n\nPython 3.10 venv for Ubuntu 21.04, Ubuntu 20.04 LTS https://www.python.org/downloads/\n\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.10\nNote For Ubuntu 18.04 Deadsnakes/ppa is not hold distribution for Ubuntu 18.04 LTS, so you need to install it manually. Download Python 3.10.0 from https://github.com/conda-forge/miniforge\nThere are 2 or 3 options for Linux architectures:\n\nLinux x86_64 (amd64)\nLinux aarch64 (arm64)\n\nGive the script execution permission and run it to install into ~/miniforge3\nchmod +x Miniforge3-Linux-x86_64.sh\n./Miniforge3-Linux-x86_64.sh\nFollow the prompts to install\n\nDownload UAV from github and create a virtual environment\n\nmkdir repos\ncd repos\ngit clone https://github.com/johnnewto/UAV.git\ncd UAV\n~/miniforge3/bin/python -m venv 'venv'\nsource ./venv/bin/activate\npip install --upgrade pip\npip install -e .\n\nInstall gstreamer\n\nsudo apt-get install libcairo2 libcairo2-dev libgirepository1.0-dev\nsudo apt install libgirepository1.0-dev\nsudo apt-get install libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio\n\nInstall gstreamer-python\n\npip install git+https://github.com/johnnewto/gstreamer-python.git\n\nAirsim ( optional for dev )\nAirSim is a simulator for drones, cars and more, built on Unreal Engine (we now also have an experimental Unity release). It is open-source, cross platform, and supports software-in-the-loop simulation with popular flight controllers such as PX4 & ArduPilot and hardware-in-loop with PX4 for physically and visually realistic simulations. It is developed as an Unreal plugin that can simply be dropped into any Unreal environment. Similarly, we have an experimental release for a Unity plugin.\nTheir goal was to develop AirSim as a platform for AI research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles. For this purpose, AirSim also exposes APIs to retrieve data and control vehicles in a platform independent way. \n\nInstall Airsim\nFor the binary releases of Airsim see https://github.com/microsoft/AirSim/releases/tag/v1.8.1 We recommend the linux version as this repo is developed on linux."
  },
  {
    "objectID": "index.html#developing-with-nbdev---initial-setup",
    "href": "index.html#developing-with-nbdev---initial-setup",
    "title": "UAV",
    "section": "Developing with nbdev - Initial setup",
    "text": "Developing with nbdev - Initial setup\nif you want to develop with nbdev, you’ll need to install it first. For a step-by-step guide to using nbdev guide to using nbdev You’ll need the following software to develope using nbdev:\n\nPython venv\nA Python package manager: ie pip\nJupyter Notebook\n\npip install jupyter\n\nnbdev\n\npip install nbdev\n\nQuarto\n\nnbdev_install_quarto\n\nInstall Quarto JupyterLab extension\n\npip install jupyterlab-quarto\n\nInstall nbdev pre-commit hooks to catch and fix uncleaned and unexported notebooks\n\npip install pre-commit\nsee nbdev Pre-Commit Hooks for more details\n\nInstall msgpack-rpc-python with tornado 4.5.3\nTo run airsim in or beside jupyter notebook you need msgpack-rpc-python to have an old version of tornado. The latest version of msgpack-rpc-python is 0.4.1, which requires tornado 4.5.3. The latest version of tornado is 6.1, which is not compatible with msgpack-rpc-python.\nThe repo https://github.com/xaedes/msgpack-rpc-python/tree/with_tornado_453 is a fork of msgpack-rpc-python which includes tornado 4.5.3 directly in the repo.\nInstall msgpack-rpc-python with integrated tornado, pip install from this repo https://github.com/johnnewto/msgpack-rpc-python/tree/with_tornado_453\npip uninstall msgpack-rpc-python\npip install git+https://github.com/johnnewto/msgpack-rpc-python.git@with_tornado_453\n\n\nPreview Docs\nStart the preview by entering this into your terminal:\nnbdev_preview\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal,\nwhich bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nUpdate Static site docs\nGenerate the static docs by entering nbdev_docs into your terminal:\n\n\nPush to GitHub\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation."
  },
  {
    "objectID": "index.html#other",
    "href": "index.html#other",
    "title": "UAV",
    "section": "Other",
    "text": "Other\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2"
  },
  {
    "objectID": "tutorials/airsim_walkthrough.html",
    "href": "tutorials/airsim_walkthrough.html",
    "title": "Airsim Walkthrough",
    "section": "",
    "text": "# logging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n#                     datefmt='%H:%M:%S',\n#                     level=logging.INFO)  # Todo add this to params\n# logger = logging.getLogger(__name__)\n\n\nfrom UAV.utils.display import *\nfrom UAV.utils.sim_linux import *\nfrom UAV.airsim.client import *\n# import UAV.utils.sim_linux as sim\n\n\nAirsim Connection\n\n\n\nRunSim\n\n RunSim (name:str='Coastline', resx:int=800, resy:int=600,\n         windowed:str|None='windowed',\n         settings:str|pathlib.Path|None=None)\n\nRun the Airsim simulator\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nCoastline\nname of the simulator environment\n\n\nresx\nint\n800\nwindow size x\n\n\nresy\nint\n600\nwindow size y\n\n\nwindowed\nstr | None\nwindowed\nwindowed or fullscreen\n\n\nsettings\nstr | Path | None\nNone\nsettings file\n\n\n\n\nrs = RunSim(\"AirSimNH\", settings=\"config/airsim_settings_high_res.json\")\n\nERROR|10.762| uav.RunSim      | sim_linux.: 73 | MainThread | MainProces | Settings file config/settings_high_res.json not found.\nINFO |10.763| uav.RunSim      | sim_linux.: 75 | MainThread | MainProces | Settings file None found.\n\n\nAirsim AirSimNH already running.\n\n\n\n\n\nAirSimClient\n\n AirSimClient (ip='', port:int=41451, timeout_value=3600)\n\nMultirotor Client for the Airsim simulator with higher level procedures\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nip\nstr\n\nrpc connection address\n\n\nport\nint\n41451\nrpc connection port\n\n\ntimeout_value\nint\n3600\ntimeout for client ping in seconds\n\n\n\n\nasc = AirSimClient()\n\nConnected!\nClient Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n\n\n\n\nSimulator assets\nassets can be listed with rs.client.simListAssets() and placed within the environment with rs.place_asset(x,y,z,asset_name)\n\n\n\nVehicleClient.simListAssets\n\n VehicleClient.simListAssets ()\n\nLists all the assets present in the Asset Registry\nReturns: list[str]: Names of all the assets\n\nassets = asc.simListAssets()\nprint(f\"Assets: {assets}\")\n\nAssets: ['Sphere', 'Cone', 'Cylinder', 'SM_SkySphere', 'Garage_Door_01offset', 'Garage_Mech_01', 'Garage_Door_02offset', 'Garage_Half_Mech_01', 'Inner_Door_01', 'Hinge_01', 'Outer_Door_01', 'Fan_Blades_01', 'Fan_Base_01', 'Outer_Wall_Quart_Win_06', 'Veranda_01', 'Street_Sign_02', 'Street_Sign_01', 'Stop_Sign_02', 'Stop_Sign_01', 'Rock_01', 'Power_Line_Connector_01', 'Power_Line_Complete_01', 'Power_Line_Cable_Single_01', 'Power_Line_Cable_01_Spline', 'Power_Line_01', 'Path_01', 'Monument_01', 'Garden_Tressel_02', 'Garden_Tressel_01', 'Garden_Rocks_01', 'Garden_Chair_01', 'Fence_01', 'Drain_Pipe_02', 'Drain_Pipe_01', 'Car_01', 'bin_02', 'bin_01', 'Bench_01', 'Basketball_Hoop_01', 'Skateboard_01', 'Plug_Socket_01', 'Picture_Frame_01', 'Paint_Can_01', 'Mug_01', 'Light_Switch_01', 'Fridge_Alphabet_01', 'extractor_01', 'Dufflebag_01', 'Drinks_Can_07', 'Drinks_Can_06', 'Drinks_Can_05', 'Drinks_Can_04', 'Drinks_Can_03', 'Drinks_Can_01', 'Curtain_03', 'Curtain_02', 'Curtain_01', 'Book_01', 'Toilet_01', 'table_01', 'Sofa_02', 'Sofa_01', 'small_table_03', 'small_table_02', 'small_table_01', 'Sink_01', 'Shutters_01', 'Shelf_01', 'Pool_Table_01', 'Office_Desk_01', 'Kitchen_Unit_Sink_01', 'Kitchen_Unit_Corner_01', 'Kitchen_Unit_02', 'Kitchen_Unit_01', 'Kitchen_Splash_Tile_01', 'Kitchen_Cupboard_Fan_01', 'Kitchen_Cupboard_02', 'Fireplace_01', 'coffee_table_02', 'coffee_table_01', 'Chair_01', 'Bookcase_02', 'Bookcase_01', 'Bed_Double_02', 'Bed_Double_01', 'Tree_01', 'Oak_03', 'Leaves_01', 'Hedge_03', 'Hedge_02', 'Hedge_01', 'Grass_Large_01', 'Grass_01', 'Fir_01', 'Daisys_01', 'Birch_01', 'Tft_01', 'Tablet_01', 'Oven_01', 'Mouse_01', 'Lcd_01', 'Laptop_01', 'Lamp_01', 'Keyboard_01', 'Headphones_01', 'Gamepad_01', 'Fridge_01', 'fan_01', 'Desktop_01', 'BRPlayer_01', 'Wall_Low_Quart_01', 'Wall_Low_Half_01', 'Wall_Low_End_01', 'Wall_Low_8th_01', 'Wall_Low_01', 'Swimming_Pool_Steps_02', 'Swimming_Pool_Steps_01', 'Swimming_Pool_Floor_01', 'Swimming_Pool_Edge_01', 'Swimming_Pool_Curve_01', 'Stairs_Beam_Quart_01', 'Staircase_Extra_Banister_01', 'Staircase_03', 'Staircase_02', 'Staircase_01', 'Banister_Roof_Angle_01', 'Banister_End_01', 'Banister_01', 'Roof_Flat_Open_Apex_01', 'Roof_Flat_Open_01', 'Roof_Flat_01', 'Roof_Quart_Open_03', 'Roof_Quart_Open_01', 'Roof_Quart_Corner_01', 'Roof_Open_01', 'Roof_Middle_Half_Half_01', 'Roof_Middle_Half_01', 'Roof_Middle_Apex_02', 'Roof_Middle_Apex_01', 'Roof_Middle_01', 'Roof_Half_01', 'Roof_End_Thin_01', 'Roof_Edge_Half_Middle_01', 'Roof_Edge_End_02', 'Roof_Edge_End_01', 'Roof_Corner_02', 'Roof_Corner_01', 'Roof_Apex_Fill_01', 'Roof_01', 'Outer_Wall_Quart_Roof_02', 'Outer_Wall_Quart_Roof_01', 'Road_Drive_Opening_03New', 'Road_Drive_Opening_02New', 'Road_Corner_01', 'Road_4Way_01NEW', 'Road_3Way_01New', 'Road_01New', 'Porch_Pillar_01', 'Porch_Middle_01', 'Porch_Corner_01', 'Porch_Banister_Quart_01', 'Porch_Banister_8th_01', 'Outdoor_Steps_01', 'Structural_Support_01', 'Outer_Wall_Quart_Win_05', 'Outer_Wall_Quart_Win_04', 'Outer_Wall_Quart_Win_03', 'Outer_Wall_Quart_Win_02', 'Outer_Wall_quart_Win_01', 'Outer_Wall_Quart_Garage_01', 'Outer_Wall_Quart_Door_03', 'Outer_Wall_quart_door_02', 'Outer_Wall_Quart_Door_01', 'Outer_Wall_Quart_01', 'Outer_Wall_Half_Win_02', 'Outer_Wall_Half_Win_01', 'Outer_Wall_Half_Garage_02', 'Outer_Wall_Half_Garage_01', 'Outer_Wall_Half_Door_01', 'Outer_Wall_Half_Apex_01', 'Outer_Wall_Half_01', 'Outer_Wall_8th_Win_01', 'Outer_Wall_8th_Door_01', 'Outer_Wall_8th_01', 'Outer_Wall_16th_01', 'Outer_Wall_01', 'House_Base_Quart_01', 'Cladding_Edge_01', '9', '7', '6', '5', '3', '2', '1', 'Inner_Wall_Roof_01', 'Inner_Wall_Quart_plus_8th_01', 'Inner_Wall_Quart_Door_01', 'Inner_Wall_Quart_Arch_01', 'Inner_Wall_Quart_01', 'Inner_Wall_Half_Door_01', 'Inner_Wall_Half_Arch_01', 'Inner_Wall_Half_01', 'Inner_Wall_Close_Gap_01', 'Inner_Wall_8th_Door_01', 'Inner_Wall_8th_Arch_01', 'Inner_Wall_8th_01', 'Inner_Wall_16th_01', 'Outer_Wall_Quart_Floor_01', 'Outer_Wall_Quart_Base_01', 'Floor_Quart_01', 'Floor_Half_Stairs_01', 'Floor_Half_Half_01', 'Floor_Half_Basic_01', 'Floor_Half_01', 'Floor_Basic_01', 'Floor_8th__01', 'Floor_01', 'Driveway_Quart_01', 'Driveway_Half_01', 'Driveway_Edge_01', 'Driveway_8th_01', 'driveway_16th_Curve_02', 'driveway_16th_Curve_01', 'Driveway_16th_01', 'Driveway_01', 'Chimney_Top_01', 'Chimney_Roof_01', 'Chimney_Mid_01', 'Chimney_Base_02', 'Chimney_Base_01', 'Cube', 'Schoolbus_Small_FixedTransforms', 'boxtruck_WithHeadlights_boxtruck_fixedtransforms_LOD0', 'Vehicle_Police_ISM', 'Ambulance_Truck_FixedTransforms', 'BicycleMan', '009_SUV_ISM_NewMat', 'Saloon_ISM_NewMat', '006_Hatchback_ISM_NewMat', 'Plane', 'S_1_Unit_Plane', 'right_OculusTouch_v3Controller', 'left_OculusTouch_v3Controller', 'right_ValveIndexController', 'left_ValveIndexController', 'GoogleDaydreamController', 'HTCViveController', 'right_OculusTouchController', 'left_OculusTouchController', 'right_MicrosoftMixedRealityController', 'left_MicrosoftMixedRealityController', 'right_OculusTouch_v2Controller', 'left_OculusTouch_v2Controller', 'OculusGoController', 'MapleLeaf01', 'Quadrotor1', 'Propeller', 'BaseAnimalBP', 'Medium_House_Prefab_01', 'Car_Porch_Prefab_01', 'Small_House_Prefab_01', 'Garage_Door_BP2', 'Inner_Door_Swing_01', 'Outer_Door_Swing_01', 'Garage_Door_Half_BP', 'Outer_Door_BP', 'Stairs_Prefab_01', 'BP_Fan_01', 'DeerBothBP', 'RaccoonBP', 'AnimalAIController', 'DmgTypeBP_Environmental', 'BP_Sky_Sphere', 'MenuActor', 'BP_CameraDirector', 'BP_PIPCamera', 'BP_ComputerVisionPawn', 'BP_FlyingPawn', 'WeatherActor', 'SuvFrontWheel', 'SuvBackWheel', 'SuvCarPawn']\n\n\n\n\n\nAirSimClient.place_object\n\n AirSimClient.place_object (name:str, x:float, y:float, z:float,\n                            scale:float=1.0, physics_enabled:bool=False)\n\nPlace an object in the simulator First check to see if the asset it is based on exists\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nasset name\n\n\nx\nfloat\n\nposition x\n\n\ny\nfloat\n\nposition y\n\n\nz\nfloat\n\nposition z\n\n\nscale\nfloat\n1.0\nscale\n\n\nphysics_enabled\nbool\nFalse\nphysics enabled\n\n\n\n\nasc.place_object(\"Sofa_02\", 5.0, 0.0, -1.0, scale=0.5 )\n\nThe sofa can be seen at the location with rs.client.simGetObjectPose(\"Sofa_02\") The sofa can be moved with rs.move_asset(x,y,z,asset_name)\n\n\n\nVehicleClient.simGetObjectPose\n\n VehicleClient.simGetObjectPose (object_name)\n\nThe position inside the returned Pose is in the world frame\nArgs: object_name (str): Object to get the Pose of\nReturns: Pose:\n\nasc.simGetObjectPose(\"Sofa_02\")\n\n&lt;Pose&gt; {   'orientation': &lt;Quaternionr&gt; {   'w_val': nan,\n    'x_val': nan,\n    'y_val': nan,\n    'z_val': nan},\n    'position': &lt;Vector3r&gt; {   'x_val': nan,\n    'y_val': nan,\n    'z_val': nan}}\n\n\n\n\n\nAirSimClient.get_image\n\n AirSimClient.get_image (camera_name:str='0', rgb2bgr:bool=False)\n\nGet an image from camera camera_name\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncamera_name\nstr\n0\ncamera name\n\n\nrgb2bgr\nbool\nFalse\nconvert to bgr\n\n\nReturns\nndarray\n\nimage\n\n\n\nShow the image with show_image(img) here we can see the camera placed at the takeoff point looking at the sofa\nTodo not sure why we have to rgd2bgr it\n\nimg = asc.get_image(rgb2bgr=True)\nax = show_image(img)\n\n\n\n\n\n\n\n\n\nimg = asc.get_image(\"center\", rgb2bgr=True)\nax = show_image(img)\n\n\n\n\n\n\n\n\n\ncams = [\"high_res\", \"front_center\", \"front_right\", \"front_left\", \"bottom_center\", \"back_center\"]\nimgs = asc.get_images(cams, rgb2bgr=True)\n\n\nfrom matplotlib import pyplot as plt\n\n\n_,axs = plt.subplots(3,2,figsize=(12,10))\nfor i,ax in enumerate(axs.flatten()): show_image(imgs[i], ax=ax, title=f' {cams[i]}')\n\n\nrs.exit()\n\n\n\nRun a loop grabbing the camera\n\nrs = RunSim(\"AirSimNH\", settings=\"config/settings_high_res.json\")\n\nasc = AirSimClient()\n\nframecounter = 1\ncam_num = 0\ncams = [\"high_res\", \"front_center\", \"front_right\", \"front_left\", \"bottom_center\", \"back_center\"]\nwith VideoWriter(\"images/airsim_test.mp4\", 5.0) as video:\n    while(True):\n        framecounter += 1\n        \n        img = asc.get_image(cams[cam_num], rgb2bgr=False)\n        puttext(img, f\"Frame: {framecounter}\")\n        img_bgr = resize(img, width=500)\n        cv2.imshow(\"Camera\", img)\n        \n        video.add(img_bgr)\n        k = cv2.waitKey(10)\n        if k == ord('q') or k == ord('Q') or k == 27:\n            break\n        \n        if k == ord('c') or k == ord('C'):\n            cam_num += 1\n            if cam_num &gt;= len(cams):\n                cam_num = 0\n            print(f\"Camera: {cams[cam_num]}\")\n        if framecounter &gt; 50:\n            break\n    cv2.destroyAllWindows()\n    rs.exit()\nvideo.show(width=500)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Airsim Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/template.html",
    "href": "tutorials/template.html",
    "title": "template01",
    "section": "",
    "text": "from UAV.imports import *   # TODO why is this relative import on ?\nfrom fastcore.utils import *\nimport cv2\nimport gi\nimport numpy as np\nfrom imutils import resize\n# from ping_ip import ping_ip\nimport threading\nfrom multiprocessing import Process\nfrom gi.repository import Gst\nimport subprocess\nimport platform\n\nimport paho.mqtt.client as mqtt_client\n\nimport time\n# from dataloader import LoadImages, resize\nfrom pathlib import Path\nimport logging\n\ngi.require_version('Gst', '1.0')\n\n\nlogging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n                    datefmt='%H:%M:%S',\n                    level=logging.DEBUG)  # Todo add this to params\nlogger = logging.getLogger(__name__)\n\nNameError: name 'logging' is not defined\n\n\nAll of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "template01"
    ]
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "UAV software is a collection of Jupyter Notebooks that are used to develop and test UAV software. The notebooks are organized into a library, and the library is used to create a documentation website and a Python package that can be installed with pip or conda (see nbdev template for an example)\n\nDocumentation is automatically generated using nbdev & Quarto and hosted on GitHub Pages. Docs support LaTeX, are searchable, and are automatically hyperlinked (including out-of-the-box support for many packages via nbdev-index)\nPublish packages to PyPI and conda as well as tools to simplify package releases. Python best practices are automatically followed, for example, only exported objects are included in __all__\nTwo-way sync between notebooks and plaintext source code allowing you to use your IDE for code navigation or quick edits\nTests written as ordinary notebook cells are run in parallel with a single command\nContinuous integration out-of-the-box with GitHub Actions that run your tests and rebuild your docs\nGit-friendly notebooks with Jupyter/Git hooks that clean unwanted metadata and render merge conflicts in a human-readable format\n… and much more!",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting Started",
    "section": "FAQ",
    "text": "FAQ\nTesting in a virtual Machine\nhttps://www.makeuseof.com/how-to-install-qemu-ubuntu-set-up-virtual-machine/\nsudo apt install qemu-kvm\nsudo apt install virt-manager\n\nCopyright\nCopyright © 2024 onward maui63.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of projects python submodules. This reference documentation is mainly useful for people looking to customise or build on top of the API, or wanting detailed information about how the API works.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nAirsim.Client\n\n\nConnects to the Airsim simulator and enables higher level procedures\n\n\n\n\nAirsim.Commands\n\n\nMulticopter higher level commands for the Airsim simulator\n\n\n\n\nCamera Fake\n\n\nOpencv and GST Fake cameras for testing\n\n\n\n\nGstreamer Python Documentation\n\n\nGstreamer python library Docs\n\n\n\n\nGstreamer raw transmit\n\n\nGstreamer video capture with on/off valve\n\n\n\n\nMavlink Camera\n\n\nMavlink Camera Component for sending commands to a camera on a companion computer or GCS\n\n\n\n\nMavlink ViewSheen Gimbal Component\n\n\nMavlink ViewSheen Camera Component for sending commands to a viewsheen gimbal on a companion computer or GCS\n\n\n\n\nParameters\n\n\nConfiguring UAV parameters\n\n\n\n\nUtils.Display\n\n\nFill in a module description here\n\n\n\n\nUtils.General\n\n\nFill in a module description here\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "API"
    ]
  },
  {
    "objectID": "api/gstreamer_python_doc.html",
    "href": "api/gstreamer_python_doc.html",
    "title": "Gstreamer Python Documentation",
    "section": "",
    "text": "from UAV.imports import *   # TODO why is this relative import on nbdev_export?\nimport cv2\nimport gi\nimport numpy as np\nfrom imutils import resize\n\nfrom PIL import Image\n\n\nimport time\n# from dataloader import LoadImages, resize\nfrom pathlib import Path\n# import logging\n\n# gi.require_version('Gst', '1.0')\n\n\nfrom gstreamer import GstPipeline, GstContext, GstVidSrcValve, GstApp, Gst, GstVideo\nimport gstreamer.utils as gst_utils\nfrom UAV.utils import *\nfrom UAV.imports import *   # TODO why is this relative import on nbdev_export?\nimport time\n\n\n\nGstVidSrcValve\n\n GstVidSrcValve (command:str, leaky:bool=False, max_buffers_size:int=100,\n                 loglevel:gstreamer.gst_tools.LogLevels=20)\n\nGstVideoSourceValve is a wrapper around a GStreamer pipeline that provides get and set methods for valve states.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncommand\nstr\n\nGst_launch string\n\n\nleaky\nbool\nFalse\nIf True -&gt; use LeakyQueue\n\n\nmax_buffers_size\nint\n100\nMax queue size\n\n\nloglevel\nLogLevels\n20\n\n\n\n\n\n\nSetup the pipeline commands\nThe valve is used to pause the video, this way we can multiplex the video stream so to conserve bandwidth\n\n\n\nGstVidSrcValve.set_valve_state\n\n GstVidSrcValve.set_valve_state (valve_name:str, dropstate:bool)\n\nSet the state of a valve in the pipeline\n\n\n\n\nType\nDetails\n\n\n\n\nvalve_name\nstr\nName of the valve in the pipeline\n\n\ndropstate\nbool\nTrue = drop, False = pass\n\n\n\nThe valve is used to pause the video, this way we can multiplex the video stream so to conserve bandwidth\n\n\n\nGstVidSrcValve.get_valve_state\n\n GstVidSrcValve.get_valve_state (valve_name:str)\n\nGet the state of a valve in the pipeline\n\n\n\n\nType\nDetails\n\n\n\n\nvalve_name\nstr\nName of the valve in the pipeline\n\n\n\n\nDEFAULT_PIPELINE = gst_utils.to_gst_string([\n            'videotestsrc pattern=ball is-live=true num-buffers=1000 ! tee name=t',\n            't.',\n            'queue leaky=2 ! valve name=myvalve drop=False ! video/x-raw,format=I420,width=640,height=480',\n            'videoconvert',\n            # 'x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast',\n            'x264enc tune=zerolatency',\n            'rtph264pay ! udpsink host=127.0.0.1 port=5000',\n            't.',\n            'queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=5/1,format=(string)BGR',\n            'videoconvert ! appsink name=mysink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n        ])\n\n\ncommand = DEFAULT_PIPELINE\nwidth, height, num_buffers = 1920, 1080, 40\nwith GstVidSrcValve(command, leaky=True) as pipeline:\n    buffers = []\n    count = 0\n    dropstate = False\n    while len(buffers) &lt; num_buffers:\n        time.sleep(0.1)\n        count += 1\n        if count % 10 == 0:\n            dropstate = not dropstate\n            pipeline.set_valve_state(\"myvalve\", dropstate)\n            print(f' {dropstate = }, {count = }')\n        buffer = pipeline.pop()\n        if buffer:\n            buffers.append(buffer)\n            # if len(buffers) % 10 == 0:\n            #     print(f'Got: {len(buffers)} buffers of {pipeline.queue_size}')\n    print('Got: {} buffers'.format(len(buffers)))\n    \n_,axs = plt.subplots(2,2,figsize=(12,10))\nfor i,ax in enumerate(axs.flatten()): show_image(buffers[i*5].data, ax=ax, title=f'image {i*5}')\n\n dropstate = True, count = 10\n dropstate = False, count = 20\n dropstate = True, count = 30\n dropstate = False, count = 40\nGot: 40 buffers\n\n\n\n\n\n\n\n\n\n\n\nShow the video on screen using two pipelines\n\nSRC_PIPELINE = gst_utils.to_gst_string([\n            'videotestsrc pattern=ball is-live=true num-buffers=1000 ! video/x-raw,framerate=5/1 !  tee name=t',\n            't.',\n            'queue leaky=2 ! valve name=myvalve drop=False ! video/x-raw,format=I420,width=640,height=480',\n            # 'textoverlay text=\"Frame: \" valignment=top halignment=left shaded-background=true',\n            # 'timeoverlay valignment=top halignment=right shaded-background=true',\n\n            'videoconvert',\n            # 'x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast',\n            'x264enc tune=zerolatency',\n            'rtph264pay ! udpsink host=127.0.0.1 port=5000',\n            't.',\n            'queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=5/1,format=(string)BGR',\n            'videoconvert ! appsink name=mysink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n        ])\nprint(SRC_PIPELINE)\nSINK_PIPELINE = gst_utils.to_gst_string([\n            'udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96',\n            'rtph264depay ! avdec_h264',\n            'fpsdisplaysink',\n            # 'autovideosink',\n        ])\n\nvideotestsrc pattern=ball is-live=true num-buffers=1000 ! video/x-raw,framerate=5/1 !  tee name=t t. ! queue leaky=2 ! valve name=myvalve drop=False ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc tune=zerolatency ! rtph264pay ! udpsink host=127.0.0.1 port=5000 t. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=5/1,format=(string)BGR ! videoconvert ! appsink name=mysink emit-signals=true  sync=false async=false  max-buffers=2 drop=true \n\n\n\nnum_buffers = 40\nwith GstPipeline(SINK_PIPELINE) as rcv_pipeline:\n    with GstVidSrcValve(SRC_PIPELINE, leaky=True) as pipeline:\n        buffers = []\n        count = 0\n        dropstate = False\n        while len(buffers) &lt; num_buffers:\n            time.sleep(0.1)\n            count += 1\n            if count % 10 == 0:\n                print(f'Count = : {count}')\n                dropstate = not dropstate\n                pipeline.set_valve_state(\"myvalve\", dropstate)\n            buffer = pipeline.pop()\n            if buffer:\n\n                buffers.append(buffer)\n                if len(buffers) % 10 == 0:\n                    print(f'Got: {len(buffers)} buffers of {pipeline.queue_size}')\n        print('Got: {} buffers'.format(len(buffers)))\n\nCount = : 10\nGot: 10 buffers of 0\nCount = : 20\nGot: 20 buffers of 0\nCount = : 30\nGot: 30 buffers of 0\nCount = : 40\nGot: 40 buffers of 0\nGot: 40 buffers\n\n\n\n# assert False, 'stop here'",
    "crumbs": [
      "Get Started",
      "API",
      "Gstreamer Python Documentation"
    ]
  },
  {
    "objectID": "api/template.html",
    "href": "api/template.html",
    "title": "Gstreamer raw transmit",
    "section": "",
    "text": "from UAV.imports import *   # TODO why is this relative import on \nfrom fastcore.utils import *\nimport cv2\nimport gi\nimport numpy as np\nfrom imutils import resize\n# from ping_ip import ping_ip\nimport threading\nfrom multiprocessing import Process\nfrom gi.repository import Gst\nimport subprocess\nimport platform\n\nimport paho.mqtt.client as mqtt_client\n\nimport time\n# from dataloader import LoadImages, resize\nfrom pathlib import Path\nimport logging\nimport UAV.params as params\n# gi.require_version('Gst', '1.0')\n\n/tmp/ipykernel_28589/164734448.py:11: PyGIWarning: Gst was imported without specifying a version first. Use gi.require_version('Gst', '1.0') before import to ensure that the right version gets loaded.\n  from gi.repository import Gst\n\n\n\nlogging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n                    datefmt='%H:%M:%S',\n                    level=params.LOGGING_LEVEL)  # Todo add this to params\nlogger = logging.getLogger(params.LOGGING_NAME)\n\nAll of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\ntest_eq(1,2)\n\nAssertionError: ==:\n1\n2",
    "crumbs": [
      "Get Started",
      "API",
      "Gstreamer raw transmit"
    ]
  },
  {
    "objectID": "api/camera.gst_cam.html",
    "href": "api/camera.gst_cam.html",
    "title": "Camera Fake",
    "section": "",
    "text": "https://mavlink.io/en/services/camera.html https://github.com/mavlink/mavlink-camera-manager\n\nimport time, os, sys\n\nfrom UAV.logging import logging\nfrom UAV.mavlink.mavcom import MAVCom, time_since_boot_ms, time_UTC_usec, date_time_str\nfrom UAV.mavlink.component import Component, mavutil, mavlink, MAVLink\n\nimport cv2\n\nfrom UAV.utils.general import boot_time_str, With, find_config_dir, read_camera_dict_from_toml\nfrom UAV.camera.gst_cam import *\n\n\n# show_doc(create_toml_file)\n\n\nimport types\n\n\ndef get_all_methods(cls):\n    methods = []\n    for name in dir(cls):\n        attr = getattr(cls, name)\n        if isinstance(attr, types.FunctionType):\n            methods.append(name)\n    return methods\n\n\nmethods = get_all_methods(GSTCamera)\nprint (methods)\n\n['__enter__', '__exit__', '__init__', '__repr__', '__str__', '_open', 'calculate_memory_usage', 'camera_capture_status_send', 'camera_image_captured_send', 'camera_information_send', 'camera_settings_send', 'close', 'get_camera_info', 'image_capture_thread_is_running', 'image_start_capture', 'image_stop_capture', 'list_files', 'load_image_from_memoryfs', 'on_capture_image', 'on_start_image_capture', 'on_status_video_capture', 'on_stop_image_capture', 'on_video_callback', 'pause', 'play', 'save_image_to_memoryfs', 'set_source_compenent', 'show_image', 'storage_information_send', 'time_UTC_usec', 'video_start_capture', 'video_start_streaming', 'video_stop_capture', 'video_stop_streaming']\n\n\n\nfor method in methods:\n    s = f\"GSTCamera.{method}\"\n    print (s)\n    show_doc(s)\n\nGSTCamera.__enter__\nGSTCamera.__exit__\nGSTCamera.__init__\nGSTCamera.__repr__\nGSTCamera.__str__\nGSTCamera._open\nGSTCamera.calculate_memory_usage\nGSTCamera.camera_capture_status_send\nGSTCamera.camera_image_captured_send\nGSTCamera.camera_information_send\nGSTCamera.camera_settings_send\nGSTCamera.close\nGSTCamera.get_camera_info\nGSTCamera.image_capture_thread_is_running\nGSTCamera.image_start_capture\nGSTCamera.image_stop_capture\nGSTCamera.list_files\nGSTCamera.load_image_from_memoryfs\nGSTCamera.on_capture_image\nGSTCamera.on_start_image_capture\nGSTCamera.on_status_video_capture\nGSTCamera.on_stop_image_capture\nGSTCamera.on_video_callback\nGSTCamera.pause\nGSTCamera.play\nGSTCamera.save_image_to_memoryfs\nGSTCamera.set_source_compenent\nGSTCamera.show_image\nGSTCamera.storage_information_send\nGSTCamera.time_UTC_usec\nGSTCamera.video_start_capture\nGSTCamera.video_start_streaming\nGSTCamera.video_stop_capture\nGSTCamera.video_stop_streaming\n\n\n\n\nGSTCamera.save_image_to_memoryfs\n\n GSTCamera.save_image_to_memoryfs (data:bytes, filename:str)\n\nSave image to memory filesystem.\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nbytes\njpeg encoded image to save\n\n\nfilename\nstr\nfilename to save image\n\n\n\n\nimport inspect\nfrom nbdev.showdoc import show_doc\n\nclass Example:\n    def method_a(self):\n        \"This is method A\"\n        pass\n    \n    def method_b(self):\n        \"This is method B\"\n        pass\n\n# To show docs for all methods in a class\nfor name, func in inspect.getmembers(Example, inspect.isfunction):\n    print(name)\n    show_doc(func)\n\nmethod_a\nmethod_b\n\n\n\nfrom nbdev.doclinks import NbdevLookup\nfrom nbdev.showdoc import _fmt_sig\n\n\ndef _html_link(url, txt): return f'{txt}'\n\nclass BasicHtmlRenderer(ShowDocRenderer):\n    \"Simple HTML renderer for `show_doc`\"\n    def _repr_html_(self):\n        doc = '\\n'\n        doc += f'{self.nm}\\n'\n        doc += f'{self.nm}{_fmt_sig(self.sig)}'\n        if self.docs: doc += f\"{self.docs}\"\n        return doc\n\n    def doc(self):\n        \"Show `show_doc` info along with link to docs\"\n        from IPython.display import display,HTML\n        res = self._repr_html_()\n        docs = NbdevLookup().doc(self.fn)\n        if docs is not None: res += '\\n' +_html_link(docs, \"Show in docs\") + ''\n        display(HTML(res))\n\n\ndef doc(elt):\n    \"Show `show_doc` info along with link to docs\"\n    BasicHtmlRenderer(elt).doc()\n\n\ndoc(GSTCamera.save_image_to_memoryfs)\n\n\nGSTCamera.save_image_to_memoryfs\nGSTCamera.save_image_to_memoryfs(data:bytes, filename:str)Save image to memory filesystem.\n\n\n\n\n\nGSTCamera.save_image_to_memoryfs\n\n GSTCamera.save_image_to_memoryfs (data:bytes, filename:str)\n\nSave image to memory filesystem.\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nbytes\njpeg encoded image to save\n\n\nfilename\nstr\nfilename to save image\n\n\n\n\n# config_path = Path(\"../../config\")\n# create_toml_file(find_config_dir()/\"____test_camera_info.toml\")\n\n\n# assert False, \"stop here\"\n\n\n# assert False, \"stop here\"\n\n\nfrom gstreamer import GstVidSrcValve,  GstVideoSave, GstJpegEnc\nimport gstreamer.utils as gst_utils\n\n\n\n\nGSTCamera\n\n GSTCamera (camera_dict=None, udp_encoder='H264', loglevel=20)\n\nCreate a fake camera component for testing using GStreamer\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncamera_dict\nNoneType\nNone\ncamera_info dict\n\n\nudp_encoder\nstr\nH264\nencoder for video streaming\n\n\nloglevel\nint\n20\nlog flag\n\n\n\n\n\n\nGSTCamera.image_start_capture\n\n GSTCamera.image_start_capture (interval, count)\n\nStart image capture sequence.\n\n\n\n\nDetails\n\n\n\n\ninterval\nImage capture interval\n\n\ncount\nNumber of images to capture (0 for unlimited)\n\n\n\n\n\n\nBaseCamera.camera_information_send\n\n BaseCamera.camera_information_send ()\n\nInformation about a camera. Can be requested with a MAV_CMD_REQUEST_MESSAGE command.\n\n\n\nCV2Camera.camera_settings_send\n\n CV2Camera.camera_settings_send ()\n\nInformation about a camera. Can be requested with a MAV_CMD_REQUEST_MESSAGE command.\n\n\n\nread_camera_dict_from_toml\n\n read_camera_dict_from_toml (toml_file_path)\n\nRead MAVLink camera info from a TOML file.\n\n\n\n\nType\nDetails\n\n\n\n\ntoml_file_path\n\npath to TOML file\n\n\nReturns\ndict\ncamera_info dict\n\n\n\n\n# with GstContext(loglevel=LogLevels.CRITICAL):  # GST main loop in thread\n#     with GstPipeline(command_h264_display, loglevel=LogLevels.INFO) as disp_pipeline:\n#         with GstPipeline(command_src, loglevel=10) as src_pipeline:\n#             with GstJpegEnc(command_jpg, max_count=5, on_jpeg_capture=on_capture, loglevel=LogLevels.INFO) as jpg_pipeline:\n#                 while not jpg_pipeline.is_done:\n#                     time.sleep(.1)\n# \n#             with GstStreamUDP(command_udp, on_callback=on_video_callback, loglevel=LogLevels.INFO) as udp_pipeline:\n#                 time.sleep(5)\n\n\nprint (f\"{boot_time_str =}\")\n# connection_string = 'udp:127.0.0.1:14550'\n# mav = mavutil.mavlink_connection(connection_string)\n\n\nwith  GSTCamera( camera_dict=read_camera_dict_from_toml(find_config_dir()/\"test_camera_info.toml\")) as cam_gst_1:\n    cam_gst_1.image_start_capture(interval=.1, count=5)\n    time.sleep(1)\n    # while cam_gst_1.pipeline.is_done is False:\n    #     # if cam_gst_1.last_image is not None:\n    #     time.sleep(0.1)\n            # cv2.imshow('image', cam_gst_1.last_image)\n            # cam_gst_1.last_image = None\n            # cv2.waitKey(10)\n            \n    # cv2.waitKey(500)\n    # cv2.destroyAllWindows()\n\nINFO   | uav.GSTCamera   | 29.670 | gst_cam.py:350 | MainThread         | GSTCamera Started\nINFO   | pygst.GstPipeli | 29.673 | gst_tools.py:223 | MainThread         | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! capsfilter caps=video/x-raw,format=RGB,width=640,height=480,framerate=10/1 ! tee name=t t. ! queue ! videoconvert ! autovideosink t. ! queue leaky=2 ! intervideosink channel=channel_0  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_1  sync=false t. ! queue leaky=2 ! intervideosink channel=channel_2  sync=false\nINFO   | pygst.GstJpegEn | 29.686 | gst_tools.py:223 | MainThread         | Starting GstJpegEnc: intervideosrc channel=channel_1   ! videoconvert ! videoscale ! video/x-raw,width=640,height=480,framerate=10/1 ! queue ! jpegenc quality=85 ! appsink name=mysink emit-signals=True max-buffers=1 drop=True\nINFO   | uav.GSTCamera   | 29.710 | gst_cam.py:577 | Thread-13 (_launch | Image saved to memory filesystem with name: 2023-10-21|10:37:29_0000.jpg\nINFO   | uav.GSTCamera   | 29.810 | gst_cam.py:577 | Thread-13 (_launch | Image saved to memory filesystem with name: 2023-10-21|10:37:29_0001.jpg\nINFO   | uav.GSTCamera   | 29.910 | gst_cam.py:577 | Thread-13 (_launch | Image saved to memory filesystem with name: 2023-10-21|10:37:29_0002.jpg\nINFO   | uav.GSTCamera   | 30.011 | gst_cam.py:577 | Thread-13 (_launch | Image saved to memory filesystem with name: 2023-10-21|10:37:30_0003.jpg\nINFO   | uav.GSTCamera   | 30.110 | gst_cam.py:577 | Thread-13 (_launch | Image saved to memory filesystem with name: 2023-10-21|10:37:30_0004.jpg\nINFO   | pygst.GstJpegEn | 30.111 | gst_tools.py:884 | Thread-13 (_launch | Sending EOS event, to trigger shutdown of pipeline\nINFO   | pygst.GstPipeli | 30.829 | gst_tools.py:306 | MainThread         | GstPipeline Shutdown\nINFO   | uav.GSTCamera   | 30.830 | gst_cam.py:518 | MainThread         | GSTCamera closed\n\n\nboot_time_str ='2023-10-21|10:29:09'\nJohn Doe",
    "crumbs": [
      "Get Started",
      "API",
      "Camera Fake"
    ]
  },
  {
    "objectID": "api/utils.display.html",
    "href": "api/utils.display.html",
    "title": "Utils.Display",
    "section": "",
    "text": "from nbdev.showdoc import *\nfrom nbdev.showdoc import *\nfrom fastcore.test import *\nimport inspect\n\n\ndef _fig_bounds(x):\n    r = x//32\n    return min(5, max(1,r))\n\n\nfrom fastcore.utils import *\nimport cv2\nimport numpy as np\nfrom imutils import resize\nfrom PIL import Image\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport moviepy.editor as mvp\nfrom moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\nimport logging\nimport UAV.params as params\nfrom UAV.utils.display import *\n\nGStreamer is not installed\n\n\n\n\nshow_image\n\n show_image (im, ax=None, figsize=None, title=None, text=None,\n             fontsize=12, ctx=None, rgb2bgr:bool=False, **kwargs)\n\nShow a PIL or PyTorch image on ax.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim\n\n\n\n\n\nax\nNoneType\nNone\nif None, a new figure is created\n\n\nfigsize\nNoneType\nNone\nif None, the figure size is set to min of 5 and max of 1/32 of the image size\n\n\ntitle\nNoneType\nNone\ntitle of the image\n\n\ntext\nNoneType\nNone\ntext to be written on image\n\n\nfontsize\nint\n12\nfontsize of text\n\n\nctx\nNoneType\nNone\ncontext\n\n\nrgb2bgr\nbool\nFalse\nconvert from/to RGB\n\n\nkwargs\n\n\n\n\n\nReturns\nplt.Axes\n\nreturn matplotlib axis\n\n\n\n\nim2 = np.array(Image.open(TEST_IMAGE))\nax = show_image(im2, text='dog', figsize=(3,3))\n\n\n\n\n\n\n\n\n\nax = show_image(im2, text='dog', figsize=(3,3), rgb2bgr=True)\n\n\n\n\n\n\n\n\n\nim2 = np.array(Image.open(TEST_IMAGE))\nim2 = puttext(im2, 'dog')\nax = show_image(im2)\n\n\n\n\n\n\n\n\n\n_,axs = plt.subplots(1,4,figsize=(12,4))\nfor i,ax in enumerate(axs): show_image(im2, ax=ax, title=f'Copy {i+1}')\n\n\n\n\n\n\n\n\n\n\n\nScrollingLog.update\n\n ScrollingLog.update (message:str, index=None)\n\nAdd a message to the log, if index is specified, update the message at the index\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmessage\nstr\n\nadd a message to the log\n\n\nindex\nNoneType\nNone\nindex of the message to be updated\n\n\n\n\n\n\nScrollingLog.draw\n\n ScrollingLog.draw (image, font=0)\n\nDraw the log on the image\nRun some tests\n\nimage = np.array(Image.open(TEST_IMAGE))\nlog = ScrollingLog()\ntest_eq(log.draw(image), None)   # runs with no log present\nfor i in range(10):\n    log.update(f\"Message {i}\")\n\ntest_eq(log.log[0], \"Message 5\")\ntest_eq(log.log[-1], \"Message 9\")\ntest_eq(len(log.log), 5)\nlog.draw(image)\n\n\nax = show_image(image)\n\n\n\n\n\n\n\n\n\n\n\nScrollingLogHandler.set_filter\n\n ScrollingLogHandler.set_filter (_filter:str)\n\nSet the filter for the log message\n\n# Standard Setting up logging\nlogging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n                        datefmt='%H:%M:%S',\n                        level=params.LOGGING_LEVEL)  # Todo add this to params\nlogger = logging.getLogger(params.LOGGING_NAME)\n\nlog = ScrollingLog(bg_color=(0,0,0))\nhandler_log = ScrollingLogHandler(log, logger, _filter='AIR')\n\n# Example usage:\nlogger.info(\"AIR: This is an info log.\")\nlogger.warning(\"This is a warning log.\")\nlogger.error(\"AIR: This is an error log.\")\nlogger.error(\"This is an error log.\")\nlogger.warning(\"AIR:This is an warning log.\")\n# Display the logs using OpenCV or your desired method\n# image = cv2.imread(\"path_to_image.jpg\")\nimage = np.array(Image.open(TEST_IMAGE))\nlog.draw(image)\nax = show_image(image[:200,:600], figsize=(5,3))\n\ntest_eq(len(log.log), 3)   # there are 3 AIR messages in the log above\n\nINFO   | uav_log         | 03.735 | 817836736.py: 11 | MainThread         | AIR: This is an info log.\nWARNIN | uav_log         | 03.737 | 817836736.py: 12 | MainThread         | This is a warning log.\nERROR  | uav_log         | 03.738 | 817836736.py: 13 | MainThread         | AIR: This is an error log.\nERROR  | uav_log         | 03.738 | 817836736.py: 14 | MainThread         | This is an error log.\nWARNIN | uav_log         | 03.738 | 817836736.py: 15 | MainThread         | AIR:This is an warning log.\n\n\n\n\n\n\n\n\n\n\nhandler_log.set_filter('')\nlogger.error(\"error1 .\")\nlogger.error(\"error2 .\")\nimage = np.array(Image.open(TEST_IMAGE))\nlog.draw(image)\nax = show_image(image[:200,:600], figsize=(5,3))\ntest_eq(len(log.log), 5)\n\nERROR  | uav_log         | 03.887 | 2590345404.py:  2 | MainThread         | error1 .\nERROR  | uav_log         | 03.888 | 2590345404.py:  3 | MainThread         | error2 .\n\n\n\n\n\n\n\n\n\n\n\nExample of use ScrollingLog with index\n\n# Simulate sequence of images\n\nimage = np.array(Image.open(TEST_IMAGE))\ndef test_log(image, max_lines=3, font_scale=2.0, index=None, bg_color=None):\n    log = ScrollingLog(max_lines=max_lines, font_scale=font_scale, bg_color=bg_color)\n    \n    # Update log messages\n    for i in range(6):\n        log.update(f\"Message {i}\")\n    log.update(f\"Mes {i+1}\")\n    \n    _,axs = plt.subplots(1,3,figsize=(16,8))\n    for i,ax in enumerate(axs.flatten()): \n        img_copy = image.copy()\n        log.update(f\"Message {i + 7}\", index=index)\n        log.draw(img_copy)\n        # just show the top left corner of the image\n        img_copy = img_copy[:img_copy.shape[0]//2, :img_copy.shape[1]//2]\n        show_image(img_copy, ax=ax, title=f'Copy {i+1}')\n\ntest_log(image, max_lines=3, font_scale=2.0, index=None, bg_color=(0,0,255))\n\n\n\n\n\n\n\n\n\ntest_log(image, max_lines=5, font_scale=1.4, index=None, bg_color=(0,0,0))\n\n\n\n\n\n\n\n\n\ntest_log(image, max_lines=8, font_scale=1.0, index=None)\n\n\n\n\n\n\n\n\n\ntest_log(image, max_lines=5, font_scale=1.4, index=6, bg_color=(0,0,0))\n\nWarning:  0 &lt;= index &lt; len(self.log)\nWarning:  0 &lt;= index &lt; len(self.log)\nWarning:  0 &lt;= index &lt; len(self.log)\n\n\n\n\n\n\n\n\n\n\nfrom UAV.utils.display import *\n\n\n\n\nVideoWriter.add\n\n VideoWriter.add (img:numpy.ndarray)\n\nAdd an image to the video\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nnp.ndarray\nimage to be added\n\n\nReturns\nNone\n\n\n\n\n\n\n\nVideoWriter.close\n\n VideoWriter.close ()\n\n\n\n\nVideoWriter.show\n\n VideoWriter.show (**kw)\n\nShow the video\n\nimport cv2\nfrom UAV.utils.display import VideoWriter, ScrollingLog, ScrollingLogHandler, puttext, show_image\nimport numpy as np\nfrom PIL import Image\nfrom fastcore.test import *\nimport logging\n\n# uncomment below to run logging on console\n# logging.basicConfig(format=\n#                     '%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n#                     datefmt='%H:%M:%S',\n#                     level=logging.INFO)  \n\nlogger = logging.getLogger(params.LOGGING_NAME) # Todo add this to params\nlogger.setLevel(params.LOGGING_LEVEL)\nlog = ScrollingLog(bg_color=(0,0,0))\nhandler_log = ScrollingLogHandler(log, logger)\nlogger.info(f\"Hello World\")\n\nimg = np.array(Image.open(TEST_IMAGE))\nframecounter = 0\nwith VideoWriter(\"images/videowriter_test.mp4\", 5.0) as video:\n# if True:\n    for i in range(20):\n        puttext(img, f\"Frame: {framecounter}\", pos=(700,80))\n        logger.info(f\"Frame: {framecounter}\")\n        log.draw(img)\n        # cv2.imshow('image', img)\n        k = cv2.waitKey(100)\n        if k == 27 or k == ord('q') or k == ord('Q'):\n            break\n        video.add(img)\n        framecounter += 1\n# cv2.destroyAllWindows()\nax=show_image(img)\n\nvideo.show(width=500)\ntest_eq(framecounter, 20)\n\nINFO   | uav_log         | 04.928 | 1743171834.py: 19 | MainThread         | Hello World\nINFO   | uav_log         | 04.934 | 1743171834.py: 27 | MainThread         | Frame: 0\nINFO   | uav_log         | 04.939 | 1743171834.py: 27 | MainThread         | Frame: 1\nINFO   | uav_log         | 04.953 | 1743171834.py: 27 | MainThread         | Frame: 2\nINFO   | uav_log         | 04.960 | 1743171834.py: 27 | MainThread         | Frame: 3\nINFO   | uav_log         | 04.965 | 1743171834.py: 27 | MainThread         | Frame: 4\nINFO   | uav_log         | 04.972 | 1743171834.py: 27 | MainThread         | Frame: 5\nINFO   | uav_log         | 04.976 | 1743171834.py: 27 | MainThread         | Frame: 6\nINFO   | uav_log         | 04.982 | 1743171834.py: 27 | MainThread         | Frame: 7\nINFO   | uav_log         | 04.987 | 1743171834.py: 27 | MainThread         | Frame: 8\nINFO   | uav_log         | 04.992 | 1743171834.py: 27 | MainThread         | Frame: 9\nINFO   | uav_log         | 04.998 | 1743171834.py: 27 | MainThread         | Frame: 10\nINFO   | uav_log         | 05.004 | 1743171834.py: 27 | MainThread         | Frame: 11\nINFO   | uav_log         | 05.009 | 1743171834.py: 27 | MainThread         | Frame: 12\nINFO   | uav_log         | 05.014 | 1743171834.py: 27 | MainThread         | Frame: 13\nINFO   | uav_log         | 05.020 | 1743171834.py: 27 | MainThread         | Frame: 14\nINFO   | uav_log         | 05.025 | 1743171834.py: 27 | MainThread         | Frame: 15\nINFO   | uav_log         | 05.030 | 1743171834.py: 27 | MainThread         | Frame: 16\nINFO   | uav_log         | 05.036 | 1743171834.py: 27 | MainThread         | Frame: 17\nINFO   | uav_log         | 05.041 | 1743171834.py: 27 | MainThread         | Frame: 18\nINFO   | uav_log         | 05.047 | 1743171834.py: 27 | MainThread         | Frame: 19\n\n\nWriting video to /home/jn/PycharmProjects/UAV/nbs/api/images/videowriter_test.mp4 at 5.0 fps.\nVideo: /home/jn/PycharmProjects/UAV/nbs/api/images/videowriter_test.mp4\n\n\nSorry, seems like your browser doesn't support HTML5 audio/video\n\n\n\n\n\n\n\n\n\n\n\n\ndoc_class\n\n doc_class (cls)\n\nDocument all the public methods in a class\n\n# show_doc(Example)\n\n\nimport asyncio\nclass Example:\n    \"\"\"This is an example class.\"\"\"\n    def __init__(self, param1:float, # param 1\n                 param2:str): # param 2\n        pass\n    def _method_a(self, param1:int, # param 1\n                 param2: int):  # param 2\n        \"This is method A\"\n        pass\n    def method_a(self, param1:int, # the param 1\n                 param2: int):  # the param 2\n        \"This is method A\"\n        pass\n    async def method_b(self, param1:int, # the param 1\n                 param2: int):  # the param 2\n        \"This is method B\"\n        pass\n\n\nExample of use doc_class\n\nfrom UAV.utils.display import doc_class\ndoc_class(Example)\n\n\n\nExample.method_a\n\n Example.method_a (param1:int, param2:int)\n\nThis is method A\n\n\n\n\nType\nDetails\n\n\n\n\nparam1\nint\nthe param 1\n\n\nparam2\nint\nthe param 2\n\n\n\n\n\n\nExample.method_b\n\n Example.method_b (param1:int, param2:int)\n\nThis is method B\nNote: async function\n\n\n\n\nDocmentTbl(Example)\n\n\n\n\n\nType\nDetails\n\n\n\n\nparam1\nfloat\nparam 1\n\n\nparam2\nstr\nparam 2\n\n\n\n\n\n\ninspect.signature(Example.method_b)\n\n&lt;Signature (self, param1: int, param2: int)&gt;\n\n\n\nsignature_ex(Example.method_b)\n\n&lt;Signature (self, param1: int, param2: int)&gt;\n\n\n\nobj = Example.method_b\nparams = L(signature_ex(obj, eval_str=True).parameters.keys())\nparams\n\n(#3) ['self','param1','param2']\n\n\n\nDocmentTbl(Example.method_b)\nDocmentTbl(Example.method_a)",
    "crumbs": [
      "Get Started",
      "API",
      "Utils.Display"
    ]
  },
  {
    "objectID": "api/mavlink.viewsheen_gimbal.html",
    "href": "api/mavlink.viewsheen_gimbal.html",
    "title": "Mavlink ViewSheen Gimbal Component",
    "section": "",
    "text": "Gimbal Component\nhttps://mavlink.io/en/services/gimbal.html\nhttps://mavlink.io/en/services/gimbal_v2.html &gt; Concepts - Gimbal Manager and Gimbal Device - To accommodate gimbals with varying capabilities, and various hardware setups, “a gimbal” is conceptually split into two parts:\nGimbal Device: the actual gimbal device, hardware and software. Gimbal Manager: software to deconflict gimbal messages and commands from different sources, and to abstract the capabilities of the Gimbal Device from gimbal users. The Gimbal Manager and Gimbal Device expose respective message sets that can be used for: gimbal manager/device discovery, querying capabilities, publishing status, and various types of orientation/attitude control.\nThe key concept to understand is that a Gimbal Manager has a 1:1 relationship with a particular Gimbal Device, and is the only party on the M\n\nimport time, os, sys\n\nfrom UAV.logging import logging\nfrom UAV.mavlink.mavcom import MAVCom\nfrom UAV.mavlink.component import Component, mavutil\n# from viewsheen_sdk.gimbal_cntrl import pan_tilt, snapshot,  zoom, VS_IP_ADDRESS, VS_PORT, KeyReleaseThread\nfrom UAV.camera_sdks.viewsheen.gimbal_cntrl import pan_tilt, snapshot,  zoom, VS_IP_ADDRESS, VS_PORT, KeyReleaseThread\n\nfrom UAV.mavlink.vs_gimbal import *\n\n# from UAV.imports import *   # TODO why is this relative import\n\n\nsource\n\n\nGimbalClient\n\n GimbalClient (source_component, mav_type, debug)\n\nCreate a Viewsheen mavlink gimbal client component for send commands to a gimbal on a companion computer or GCS\n\n\n\n\nDetails\n\n\n\n\nsource_component\nused for component indication\n\n\nmav_type\nused for heartbeat MAV_TYPE indication\n\n\ndebug\nlogging level\n\n\n\n\nsource\n\n\nGimbalServer\n\n GimbalServer (source_component, mav_type, debug)\n\nCreate a Viewsheen mavlink Camera Server Component for receiving commands from a gimbal on a companion computer or GCS\n\n\n\n\nDetails\n\n\n\n\nsource_component\nused for component indication\n\n\nmav_type\nused for heartbeat MAV_TYPE indication\n\n\ndebug\nlogging level\n\n\n\n\nMAV_TYPE_GCS = mavutil.mavlink.MAV_TYPE_GCS\nMAV_TYPE_CAMERA = mavutil.mavlink.MAV_TYPE_CAMERA\n# cli = GimbalClient(mav_connection=None, source_component=11, mav_type=MAV_TYPE_GCS, debug=False)\n# gim1 = GimbalServer(mav_connection=None, source_component=22, mav_type=MAV_TYPE_CAMERA, debug=False)\n\ncon1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n# con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\nwith MAVCom(con1, source_system=111, debug=False) as client:\n    with MAVCom(con2, source_system=222, debug=False) as server:\n        gimbal:GimbalClient = client.add_component(GimbalClient( mav_type=MAV_TYPE_GCS, source_component = 11, debug=False))\n        server.add_component(GimbalServer( mav_type=MAV_TYPE_CAMERA, source_component = 22, debug=False))\n        \n        gimbal.wait_heartbeat(target_system=222, target_component=22, timeout=0.99)\n        time.sleep(0.1)\n        gimbal.set_target(222, 22)\n        \n        NAN = float(\"nan\")\n        # client.component[11]._test_command(222, 22, 1)\n        # for i in range (1)  :\n        #     time.sleep(0.01)\n        gimbal.set_attitude( NAN, NAN, 0.0, 0.2)\n        time.sleep(0.5)\n        gimbal.set_attitude( NAN, NAN, 0.0, -0.2)\n        time.sleep(0.5)\n        gimbal.start_capture()\n        # gimbal.set_zoom(1)\n        \n        \n        # client.component[11].set_attitude(0, 0, 0, 0, 0, 0)\n\nINFO   | uav.MAVCom      | 44.813 |  mavcom.py:393 | Thread-7 (listen)  | MAVLink Mav2: True, source_system: 111\nINFO   | uav.MAVCom      | 44.915 |  mavcom.py:393 | Thread-8 (listen)  | MAVLink Mav2: True, source_system: 222\nINFO   | uav.GimbalClien | 44.917 | component.py:111 | MainThread         | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO   | uav.MAVCom      | 52.945 |  mavcom.py:441 | MainThread         | MAVCom  closed\nINFO   | uav.GimbalClien | 53.953 | component.py:366 | MainThread         | GimbalClient closed\nINFO   | uav.MAVCom      | 53.955 |  mavcom.py:441 | MainThread         | MAVCom  closed\n\n\nset_mav_connection GimbalClient mavcom.py:107 self.mav_connection = &lt;MAVCom&gt;\n\n\nKeyboardInterrupt: \n\n\n\n# assert False, \"Stop here\"",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink ViewSheen Gimbal Component"
    ]
  },
  {
    "objectID": "api/airsim.client.html",
    "href": "api/airsim.client.html",
    "title": "Airsim.Client",
    "section": "",
    "text": "from UAV.airsim_python_client import MultirotorClient\nimport UAV.params as params\nfrom UAV.utils import config_dir\nimport logging\nfrom UAV.airsim.client import AirSimClient\n\n\nlogging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n                    datefmt='%H:%M:%S',\n                    level=params.LOGGING_LEVEL)\nlogger = logging.getLogger(params.LOGGING_NAME)\n\n\nfrom UAV.utils.display import *\nfrom UAV.utils.sim_linux import *\nfrom matplotlib import pyplot as plt\n\n\n\nRunSim\n\n RunSim (name:str='Coastline', resx:int=1600, resy:int=1200,\n         windowed:str|None='windowed',\n         settings:str|pathlib.Path|None=None)\n\nRun the Airsim simulator\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nCoastline\nname of the simulator environment\n\n\nresx\nint\n1600\nwindow size x\n\n\nresy\nint\n1200\nwindow size y\n\n\nwindowed\nstr | None\nwindowed\nwindowed or fullscreen\n\n\nsettings\nstr | Path | None\nNone\nsettings file\n\n\n\n\nrs = RunSim(\"AirSimNH\", settings=config_dir() / \"airsim_settings_high_res.json\")\n\nINFO |30.895| uav.RunSim      | sim_linux.: 75 | MainThread | MainProces | Settings file /home/john/PycharmProjects/UAV/config/airsim_settings_high_res.json found.\n\n\nStarting Airsim  ['/home/john/Airsim/AirSimNH/LinuxNoEditor/AirSimNH/Binaries/Linux/AirSimNH', '-ResX=1600', '-ResY=1200', '-windowed', '-settings=/home/john/PycharmProjects/UAV/config/airsim_settings_high_res.json']\nStarted Airsim AirSimNH\n\n\n\n\n\nAirSimClient\n\n AirSimClient (ip='', port:int=41451, timeout_value=3600)\n\nMultirotor Client for the Airsim simulator with higher level procedures\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nip\nstr\n\nrpc connection address\n\n\nport\nint\n41451\nrpc connection port\n\n\ntimeout_value\nint\n3600\ntimeout for client ping in seconds\n\n\n\n\n\n\nAirSimClient.place_object\n\n AirSimClient.place_object (name:str, x:float, y:float, z:float,\n                            scale:float=1.0, physics_enabled:bool=False)\n\nPlace an object in the simulator First check to see if the asset it is based on exists\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nasset name\n\n\nx\nfloat\n\nposition x\n\n\ny\nfloat\n\nposition y\n\n\nz\nfloat\n\nposition z\n\n\nscale\nfloat\n1.0\nscale\n\n\nphysics_enabled\nbool\nFalse\nphysics enabled\n\n\n\n\nasc = AirSimClient()\n\nConnected!\nClient Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n\n\n\nasc.place_object(\"Sofa_02\", 5.0, 0.0, -1.0, scale=0.5 )\n\nThe sofa can be seen at the location with rs.client.simGetObjectPose(\"Sofa_02\") The sofa can be moved with rs.move_asset(x,y,z,asset_name)\n\nasc.simGetObjectPose(\"Sofa_02\")\n\n&lt;Pose&gt; {   'orientation': &lt;Quaternionr&gt; {   'w_val': nan,\n    'x_val': nan,\n    'y_val': nan,\n    'z_val': nan},\n    'position': &lt;Vector3r&gt; {   'x_val': nan,\n    'y_val': nan,\n    'z_val': nan}}\n\n\n\n#### Get image from one camera\n\n\n\n\nAirSimClient.get_image\n\n AirSimClient.get_image (camera_name:str='0', rgb2bgr:bool=False)\n\nGet an image from cameras camera_name\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncamera_name\nstr\n0\ncameras name\n\n\nrgb2bgr\nbool\nFalse\nconvert to bgr\n\n\nReturns\nndarray\n\nimage\n\n\n\n\nimg = asc.get_image(rgb2bgr=True)\nax = show_image(img)\n\n\n\n\n\n\n\n\n\n\n\nAirSimClient.get_images\n\n AirSimClient.get_images (camera_names:list=['0'], rgb2bgr:bool=False)\n\nGet images from the simulator of cameras camera_names\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncamera_names\nlist\n[‘0’]\ncameras names\n\n\nrgb2bgr\nbool\nFalse\nconvert to rgb\n\n\nReturns\nlist\n\nimages\n\n\n\n\ncams = [\"center\", \"right\", \"left\", \"down\"]\nimgs = asc.get_images(cams, rgb2bgr=True)\n\n_,axs = plt.subplots(2,2,figsize=(12,10))\nfor i,ax in enumerate(axs.flatten()): show_image(imgs[i], ax=ax, title=f' {cams[i]}')\n\n\n\n\n\n\n\n\n\nrs.exit()\n\nAirsim exited with rc = 143",
    "crumbs": [
      "Get Started",
      "API",
      "Airsim.Client"
    ]
  },
  {
    "objectID": "api/mavlink.camera.html",
    "href": "api/mavlink.camera.html",
    "title": "Mavlink Camera",
    "section": "",
    "text": "import time\nfrom UAV.cameras.gst_cam import GSTCamera\nfrom UAV.logging import LogLevels\nfrom UAV.manager import Gui\nfrom UAV.mavlink import CameraClient, CameraServer, MAVCom, mavlink, GimbalServerViewsheen\n\n\nfrom UAV.mavlink.camera_client import *\nfrom UAV.mavlink.camera_server import *\nfrom UAV.utils.display import *\nfrom fastcore.test import *\n\nBtn_State.RUNNING = 1\n\n\n\nImplementation of these commands:\n\nMAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS = 527 MAV_CMD_REQUEST_CAMERA_INFORMATION = 523 MAV_CMD_REQUEST_CAMERA_SETTINGS = 524 MAV_CMD_REQUEST_STORAGE_INFORMATION = 525 MAV_CMD_STORAGE_FORMAT = 526 MAV_CMD_SET_CAMERA_ZOOM = 531 MAV_CMD_SET_CAMERA_FOCUS = 532 MAV_CMD_IMAGE_START_CAPTURE = 2000 MAV_CMD_IMAGE_STOP_CAPTURE = 2001\nMAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION = 2504 MAV_CMD_REQUEST_VIDEO_STREAM_STATUS = 2505 MAV_CMD_VIDEO_START_CAPTURE = 2500 MAV_CMD_VIDEO_STOP_CAPTURE = 2501 MAV_CMD_SET_CAMERA_MODE = 530\nNote The simulated camera is implemented in PX4 gazebo_camera_manager_plugin.cpp.\n\n\n# from pymavlink.dialects.v20 import ardupilotmega as mav\n# from pymavlink.dialects.v20.ardupilotmega import MAVLink\n\n\nNAN = float(\"nan\")\n\n\"\"\"\nMAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS = 527 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_CAPTURE_STATUS\nMAV_CMD_REQUEST_CAMERA_INFORMATION = 521 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_INFORMATION\nMAV_CMD_REQUEST_CAMERA_SETTINGS = 522 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_CAMERA_SETTINGS\nMAV_CMD_REQUEST_STORAGE_INFORMATION = 525 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_STORAGE_INFORMATION\nMAV_CMD_STORAGE_FORMAT = 526 # https://mavlink.io/en/messages/common.html#MAV_CMD_STORAGE_FORMAT\nMAV_CMD_SET_CAMERA_ZOOM = 531 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_ZOOM\nMAV_CMD_SET_CAMERA_FOCUS = 532 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_FOCUS\nMAV_CMD_IMAGE_START_CAPTURE = 2000  # https://mavlink.io/en/messages/common.html#MAV_CMD_IMAGE_START_CAPTURE\nMAV_CMD_IMAGE_STOP_CAPTURE = 2001  # https://mavlink.io/en/messages/common.html#MAV_CMD_IMAGE_STOP_CAPTURE\nMAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION = 2504 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_VIDEO_STREAM_INFORMATION\nMAV_CMD_REQUEST_VIDEO_STREAM_STATUS = 2505 # https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_VIDEO_STREAM_STATUS\nMAV_CMD_VIDEO_START_CAPTURE = 2500 # https://mavlink.io/en/messages/common.html#MAV_CMD_VIDEO_START_CAPTURE\nMAV_CMD_VIDEO_STOP_CAPTURE = 2501 # https://mavlink.io/en/messages/common.html#MAV_CMD_VIDEO_STOP_CAPTURE\nMAV_CMD_SET_CAMERA_MODE = 530 # https://mavlink.io/en/messages/common.html#MAV_CMD_SET_CAMERA_MODE\n\n\"\"\"\nCAMERA_INFORMATION = mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION # https://mavlink.io/en/messages/common.html#CAMERA_INFORMATION\nCAMERA_SETTINGS = mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS # https://mavlink.io/en/messages/common.html#CAMERA_SETTINGS\nSTORAGE_INFORMATION = mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION # https://mavlink.io/en/messages/common.html#STORAGE_INFORMATION\nCAMERA_CAPTURE_STATUS = mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS # https://mavlink.io/en/messages/common.html#CAMERA_CAPTURE_STATUS\nCAMERA_IMAGE_CAPTURED = mavlink.MAVLINK_MSG_ID_CAMERA_IMAGE_CAPTURED # https://mavlink.io/en/messages/common.html#CAMERA_IMAGE_CAPTURED\n\n\n\nCamera Server\n\nThe server is on the companion computer and is used to receive commands from the camera on the ground station PC.\n\n\n\n\nCameraServer\n\n CameraServer (source_component=100, mav_type=30, camera=None,\n               loglevel:UAV.logging.LogLevels|int=20)\n\nCreate a mavlink Camera server Component, cameras argument will normally be a gstreamer pipeline\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsource_component\nint\n100\nused for component indication\n\n\nmav_type\nint\n30\nused for heartbeat MAV_TYPE indication\n\n\ncamera\nNoneType\nNone\ncameras (or FakeCamera for testing)\n\n\nloglevel\nLogLevels | int\n20\nlogging level\n\n\n\n\n# run a server that can receive commands from a client\nfrom UAV.logging import LogLevels\n\n# start a mavlink server that can receive commands from a client\nwith MAVCom(\"udpout:localhost:14445\", source_system=222, loglevel=LogLevels.DEBUG) as UAV_server:\n    # add the camera server components to the server\n    UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=None))\n    UAV_server.add_component(CameraServer(mavlink.MAV_COMP_ID_CAMERA2))\n    UAV_server.add_component(CameraServer(mavlink.MAV_COMP_ID_CAMERA3))\n    \n    time.sleep(1)\n\nINFO |28.955| mavcom.MAVCom   | mavcom.py :386 | Thread-6 ( | MainProces | MAVLink Mav2: True, source_system: 222\nWARNI|28.957| mavcom.CameraSe | camera_ser:114 | MainThread | MainProces | Component has no cameras object\nINFO |28.957| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nWARNI|28.958| mavcom.CameraSe | camera_ser:114 | MainThread | MainProces | Component has no cameras object\nINFO |28.958| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 101, self.mav_type = 30, self.source_system = 222\nWARNI|28.959| mavcom.CameraSe | camera_ser:114 | MainThread | MainProces | Component has no cameras object\nINFO |28.959| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 102, self.mav_type = 30, self.source_system = 222\nINFO |30.959| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |30.960| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |30.960| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |30.960| mavcom.MAVCom   | mavcom.py :442 | MainThread | MainProces | MAVCom  closed\n\n\nUAV                             \nUAV                             \nUAV                             \n\n\n\nCameraServer().list_commands()\n\nSupported Commands: https://mavlink.io/en/messages/common.html#mav_commands\n Cmd = MAV_CMD_REQUEST_MESSAGE: 512 \n Cmd = MAV_CMD_STORAGE_FORMAT: 526 \n Cmd = MAV_CMD_SET_CAMERA_ZOOM: 531 \n Cmd = MAV_CMD_IMAGE_START_CAPTURE: 2000 \n Cmd = MAV_CMD_IMAGE_STOP_CAPTURE: 2001 \n Cmd = MAV_CMD_VIDEO_START_CAPTURE: 2500 \n Cmd = MAV_CMD_VIDEO_STOP_CAPTURE: 2501 \n Cmd = MAV_CMD_SET_CAMERA_MODE: 530 \n Cmd = MAV_CMD_VIDEO_START_STREAMING: 2502 \n Cmd = MAV_CMD_VIDEO_STOP_STREAMING: 2503 \nSupported Message Requests:  https://mavlink.io/en/messages/common.html#messages\n\nMAVLINK_MSG_ID_CAMERA_INFORMATION:  259\nMAVLINK_MSG_ID_CAMERA_SETTINGS:  260\nMAVLINK_MSG_ID_STORAGE_INFORMATION:  261\nMAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS:  262\nMAVLINK_MSG_ID_CAMERA_IMAGE_CAPTURED:  263\nMAVLINK_MSG_ID_VIDEO_STREAM_INFORMATION:  269\nMAVLINK_MSG_ID_VIDEO_STREAM_STATUS:  270\n\n\n\n\nCamera Client\n\nThe client is on the ground station PC and is used to send commands to the camera on the companion computer.\n\n\n\n\nCameraClient\n\n CameraClient (source_component:int, mav_type:int,\n               loglevel:UAV.logging.LogLevels|int=20)\n\nCreate a client component to send commands to a companion computer or GCS that will control a cameras via a CameraServer instance\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsource_component\nint\n\nused for component indication\n\n\nmav_type\nint\n\nused for heartbeat MAV_TYPE indication\n\n\nloglevel\nLogLevels | int\n20\nlogging level\n\n\n\n\nExample: CameraClient\n\n# run a client that can send commands to a server\nwith MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.CRITICAL) as client: \n    # add the camera client component to the client\n    gcs:CameraClient = client.add_component( CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11, loglevel=LogLevels.DEBUG) )\n\nDEBUG|31.104| mavcom.CameraCl | basecompon:119 | MainThread | MainProces | set_mav_connection CameraClient general.py:119 self.mav_com = &lt;MAVCom&gt;\nDEBUG|31.104| mavcom.CameraCl | basecompon:165 | Thread-16  | MainProces | Starting heartbeat type: 6 to all Systems and Components\nDEBUG|31.105| mavcom.CameraCl | basecompon:127 | MainThread | MainProces | Called from Component.start_mav_connection(), override to add startup behaviour\nDEBUG|31.105| mavcom.CameraCl | basecompon:168 | Thread-16  | MainProces | Sent heartbeat 6 self.source_system = 111 self.source_component = 11\nINFO |31.105| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO |32.105| mavcom.CameraCl | basecompon:417 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)\nDEBUG|32.107| mavcom.CameraCl | basecompon:168 | Thread-16  | MainProces | Sent heartbeat 6 self.source_system = 111 self.source_component = 11\n\n\n\ndoc_class(CameraClient)\n\n\n\nBaseComponent.append_message_handler\n\n BaseComponent.append_message_handler (callback:Callable)\n\nappend the callback function for when a command is received.\n\n\n\nBaseComponent.close\n\n BaseComponent.close ()\n\n\n\n\nBaseComponent.count_message\n\n BaseComponent.count_message (msg)\n\nCount a message by adding it to the message_cnts dictionary. indexed by system and message type\n\n\n\nCameraClient.image_start_capture\n\n CameraClient.image_start_capture (target_system=None,\n                                   target_component=None, interval=0,\n                                   count=1)\n\nStart image capture sequence.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\ninterval\nint\n0\nImage capture interval\n\n\ncount\nint\n1\nNumber of images to capture (0 for unlimited)\n\n\n\n\n\n\nCameraClient.image_stop_capture\n\n CameraClient.image_stop_capture (target_system=None,\n                                  target_component=None)\n\nStop image capture sequence\n\n\n\nComponent.message_callback_cond\n\n Component.message_callback_cond (msg_id, target_system, target_component,\n                                  timeout=1)\n\nRegister a callback for a message received from a component server Returns the message\nNote: async function\n\n\n\nComponent.on_mav_connection\n\n Component.on_mav_connection ()\n\n\n\n\nComponent.on_message\n\n Component.on_message\n                       (msg:pymavlink.dialects.v20.ardupilotmega.MAVLink_m\n                       essage)\n\nCallback for a command received from a component server\n\n\n\nComponent.request_message\n\n Component.request_message (msg_id, params=None, target_system=None,\n                            target_component=None, timeout=1)\n\nRequest the target system(s) emit a single instance of a specified message (i.e. a “one-shot” version of MAV_CMD_SET_MESSAGE_INTERVAL). https://mavlink.io/en/messages/common.html#MAV_CMD_REQUEST_MESSAGE\nNote: async function\n\n\n\nComponent.request_message_stream\n\n Component.request_message_stream (target_system=None,\n                                   target_component=None, msg_id:int=147,\n                                   interval:int=1000000,\n                                   response_target:int=0)\n\nA system can request that additional messages are sent as a stream, or change the rate at which existing streamed messages are sent, using the MAV_CMD_SET_MESSAGE_INTERVAL command. A single instance of a message can be requested by sending MAV_CMD_REQUEST_MESSAGE. See https://mavlink.io/en/mavgen_python/howto_requestmessages.html See https://mavlink.io/en/messages/common.html#MAV_CMD_SET_MESSAGE_INTERVAL\nNote: async function\n\n\n\nBaseComponent.send_ack\n\n BaseComponent.send_ack (msg, ack_result:object=0)\n\nSend an ACK message to indicate a command was received.\n\n\n\nBaseComponent.send_command\n\n BaseComponent.send_command (target_system:int, target_component:int,\n                             command_id:int, params:list, timeout=0.5)\n\nNote: async function\n\n\n\nComponent.send_message\n\n Component.send_message (msg)\n\nSend a message to a component server\n\n\n\nBaseComponent.send_ping\n\n BaseComponent.send_ping (target_system:int, target_component:int,\n                          ping_num:int=None)\n\nSend self.max_pings * ping messages to test if the server is alive.\n\n\n\nCameraClient.set_camera_mode\n\n CameraClient.set_camera_mode (target_system=None, target_component=None,\n                               mode_id=0)\n\nSet the camera mode\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nmode_id\nint\n0\nhttps://mavlink.io/en/messages/common.html#CAMERA_MODE\n\n\n\n\n\n\nCameraClient.set_camera_zoom\n\n CameraClient.set_camera_zoom (target_system=None, target_component=None,\n                               zoom_type=0, zoom_value=1)\n\nSet the cameras zoom\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nzoom_type\nint\n0\n\n\n\nzoom_value\nint\n1\n0 to 100 zoom value\n\n\n\n\n\n\nBaseComponent.set_log\n\n BaseComponent.set_log (loglevel)\n\n\n\n\nBaseComponent.set_mav_connection\n\n BaseComponent.set_mav_connection (mav_com:MAVCom)\n\nSet the mav_connection for the component\n\n\n\nComponent.set_message_callback_cond\n\n Component.set_message_callback_cond (msg_id, target_system,\n                                      target_component)\n\nRegister a callback condition for a message received from a component server\n\n\n\nBaseComponent.set_source_compenent\n\n BaseComponent.set_source_compenent ()\n\nSet the source component for the master.mav\n\n\n\nBaseComponent.set_target\n\n BaseComponent.set_target (target_system, target_component)\n\nSet the target system and component for the gimbal\n\n\n\nCameraClient.storage_format\n\n CameraClient.storage_format (target_system=None, target_component=None)\n\nFormat storage (for cases where cameras has storage)\n\n\n\nBaseComponent.test_command\n\n BaseComponent.test_command (target_system:int, target_component:int,\n                             camera_id:int)\n\nexample: MAV_CMD_DO_DIGICAM_CONTROL to trigger a cameras\nNote: async function\n\n\n\nCameraClient.video_start_capture\n\n CameraClient.video_start_capture (target_system=None,\n                                   target_component=None,\n                                   video_stream_id=0, frequency=1)\n\nStart video capture\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\n\n\n\nfrequency\nint\n1\nFrequency CAMERA_CAPTURE_STATUS messages should be sent while recording (0 for no messages, otherwise frequency in Hz)\n\n\n\n\n\n\nCameraClient.video_start_streaming\n\n CameraClient.video_start_streaming (target_system=None,\n                                     target_component=None,\n                                     video_stream_id=0)\n\nStart video streaming\n\n\n\nCameraClient.video_stop_capture\n\n CameraClient.video_stop_capture (target_system=None,\n                                  target_component=None,\n                                  video_stream_id=0)\n\nStop video capture\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo stream id (0 for all streams)\n\n\n\n\n\n\nCameraClient.video_stop_streaming\n\n CameraClient.video_stop_streaming (target_system=None,\n                                    target_component=None,\n                                    video_stream_id=0)\n\nStop the video stream\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntarget_system\nNoneType\nNone\n\n\n\ntarget_component\nNoneType\nNone\n\n\n\nvideo_stream_id\nint\n0\nVideo Stream ID (0 for all streams)\n\n\n\n\n\n\nBaseComponent.wait_ack\n\n BaseComponent.wait_ack (target_system, target_component, command_id=None,\n                         timeout=0.1)\n\nWait for an ack from target_system and target_component.\nNote: async function\n\n\n\nBaseComponent.wait_heartbeat\n\n BaseComponent.wait_heartbeat (remote_mav_type=None, target_system=None,\n                               target_component=None, timeout:float=1.0)\n\nWait for a heartbeat from target_system and target_component.\nNote: async function\n\n\n\nComponent.wait_message_callback\n\n Component.wait_message_callback (cond, timeout=1, remove_after=True)\n\nWait for the callback for a message received from a component server\nNote: async function\n\n\n\n\n\n\nExample: Test locally using UDP ports\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222 CameraClient is set to udpin:localhost:14445 and CameraServer is set to udpout:localhost:14445 udpin is so that the client can receive UDP from the mavproxy server at localhost:14445 CameraClient uses async/await to send commands to the CameraServer\n\n\nimport asyncio\nasync def main():\n    MAV_TYPE_GCS = mavlink.MAV_TYPE_GCS\n    MAV_TYPE_CAMERA = mavlink.MAV_TYPE_CAMERA\n    \n    con1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\n    with MAVCom(con1, source_system=111) as client:\n        with MAVCom(con2, source_system=222) as server:\n            gcs:CameraClient = client.add_component(\n                CameraClient(mav_type=MAV_TYPE_GCS, source_component=11))\n            # server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=cam_fake1, debug=False))\n            server.add_component(CameraServer(mav_type=MAV_TYPE_CAMERA, source_component=22, camera=None))\n    \n            ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n            print(f\"Heartbeat received {ret = }\")\n    \n            msg = await gcs.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=22)\n\n            print( f\"MAVLINK_MSG_ID_CAMERA_INFORMATION {msg}\")\n            \n            # msg = await cam.request_storage_information()\n            # print (msg)\n            \n            time.sleep(1)\n            \nawait main()\n\nINFO |32.270| mavcom.MAVCom   | mavcom.py :386 | Thread-18  | MainProces | MAVLink Mav2: True, source_system: 111\nINFO |32.370| mavcom.MAVCom   | mavcom.py :386 | Thread-19  | MainProces | MAVLink Mav2: True, source_system: 222\nINFO |32.372| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nWARNI|32.373| mavcom.CameraSe | camera_ser:114 | MainThread | MainProces | Component has no cameras object\nINFO |32.374| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 22, self.mav_type = 30, self.source_system = 222\nINFO |34.374| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |34.375| mavcom.MAVCom   | mavcom.py :442 | MainThread | MainProces | MAVCom  closed\nINFO |34.375| mavcom.CameraCl | basecompon:417 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)\nINFO |34.376| mavcom.MAVCom   | mavcom.py :442 | MainThread | MainProces | MAVCom  closed\n\n\nUAV                             \nHeartbeat received ret = (222, 22)\nMAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 3985, vendor_name : UAV, model_name : FakeCamera, firmware_version : 1, focal_length : 2.799999952316284, sensor_size_h : 3.200000047683716, sensor_size_v : 2.4000000953674316, resolution_h : 640, resolution_v : 480, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : , gimbal_device_id : 0}\n\n\n\nStarting a client and server\n\non the same machine using UDP ports 14445 with server_system_ID=111, client_system_ID=222\n\n\nfrom UAV.mavlink import CameraClient, CameraServer, MAVCom, mavlink, GimbalServerViewsheen\n\nimport time\n\ndef on_message(message):\n    print(f\"on_message: {message}\")\n    return True # Return True to indicate that command was ok and send ack\n\nclass Cam1(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self.append_message_handler(on_message)\n\n\nclass Cam2(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self.append_message_handler(on_message)\n\n\nclass Cli(Component):\n    def __init__(self, source_component, mav_type, debug=False):\n        super().__init__(source_component=source_component, mav_type=mav_type)\n        self.append_message_handler(on_message)\n\n\n# assert False, \"Stop here\"\n\n\n\nTest with Serial ports\nTest using a Pixhawk connected via telemetry 2 and USB serial ports. CamClient is set to udpin:localhost:14445 and CamServer is set to udpout:localhost:14435 udpin is so that the client can receive UDP from the mavproxy server at localhost:14445 mavproxy.py –master=/dev/ttyACM1 –baudrate 57600 –out udpout:localhost:14445 mavproxy.py –master=/dev/ttyACM3 –baudrate 57600 –out udpout:localhost:14435\n\n# Test sending a command and receiving an ack from client to server\nwith MAVCom(\"/dev/ttyACM0\", source_system=111) as client:\n    with MAVCom(\"/dev/ttyUSB0\", source_system=222) as server:\n        client.add_component(Cli(client, mav_type=mavlink.MAV_TYPE_GCS))\n        server.add_component(Cam1(server, mav_type=mavlink.MAV_TYPE_CAMERA))\n        server.add_component(Cam1(server, mav_type=mavlink.MAV_TYPE_CAMERA))\n        \n        for key, comp in client.component.items():\n            if comp.wait_heartbeat(target_system=222, target_component=22, timeout=0.1):\n                print (\"*** Received heartbeat **** \" )\n        NUM_TO_SEND = 2\n        for i in range(NUM_TO_SEND):\n            client.component[11]._test_command(222, 22, 1)\n            client.component[11]._test_command(222, 23, 1)\n            \n        client.component[11]._test_command(222, 24, 1)\n\n    print(f\"{server.source_system = };  {server.message_cnts = }\")\n    print(f\"{client.source_system = };  {client.message_cnts = }\")\n    print()\n    print(f\"{client.source_system = } \\n{client.summary()} \\n\")\n    print(f\"{server.source_system = } \\n{server.summary()} \\n\")\n\n    assert client.component[11].num_cmds_sent == NUM_TO_SEND * 2 + 1\n    assert client.component[11].num_acks_rcvd == NUM_TO_SEND * 2\n    assert client.component[11].num_acks_drop == 1\n    assert server.component[22].num_cmds_rcvd == NUM_TO_SEND\n    assert server.component[23].num_cmds_rcvd == NUM_TO_SEND\n\nERROR|34.431| mavcom.MAVCom   | mavcom.py :296 | MainThread | MainProces | [Errno 2] could not open port /dev/ttyACM0: [Errno 2] No such file or directory: '/dev/ttyACM0'\n\n\nSerialException: [Errno 2] could not open port /dev/ttyACM0: [Errno 2] No such file or directory: '/dev/ttyACM0'\n\n\n\nFor debugging help see http://localhost:3000/tutorials/mavlink_doc&debug.html and http://localhost:3000/tutorials/mavlink_doc&debug.html#debugging",
    "crumbs": [
      "Get Started",
      "API",
      "Mavlink Camera"
    ]
  },
  {
    "objectID": "api/utils.general.html",
    "href": "api/utils.general.html",
    "title": "Utils.General",
    "section": "",
    "text": "from fastcore.utils import *\nfrom fastcore.utils import *\nimport numpy as np # Scientific computing library for Python\nimport queue\nimport typing as typ\nfrom UAV.utils.general import *\n\n\nsource\n\nLeakyQueue\n\n LeakyQueue (maxsize:int=100, on_drop:Optional[Callable[[ForwardRef('Leaky\n             Queue'),ForwardRef('object')],NoneType]]=None)\n\nQueue that contains only the last actual items and drops the oldest one.\n\nsource\n\n\neuler_to_quaternion\n\n euler_to_quaternion (roll:float, pitch:float, yaw:float)\n\nConvert an Euler angle to a quaternion.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nroll\nfloat\nroll (rotation around x-axis) angle in radians\n\n\npitch\nfloat\nattitude (rotation around y-axis) angle in radians\n\n\nyaw\nfloat\ndirection (rotation around z-axis) angle in radians\n\n\nReturns\nlist\norientation in quaternion [x,y,z,w] format\n\n\n\nRun some tests",
    "crumbs": [
      "Get Started",
      "API",
      "Utils.General"
    ]
  },
  {
    "objectID": "api/params.html",
    "href": "api/params.html",
    "title": "Parameters",
    "section": "",
    "text": "_uav_home_dir = 'UAV' # subdirectory of xdg base dir\n_uav_cfg_name = 'settings.toml'    # todo use https://github.com/hukkin/tomli\n_uav_params_name = 'params.py'\n\n\n\n\nimport logging\n\n\nLOG_DIR = 'logs'\nLOGGING_LEVEL = logging.INFO\nLOGGING_NAME = 'uav_log'\n\n\n# test_eq(cfg.doc_path, p/'_docs')\n# test_eq(cfg.lib_path, p/'nbdev')\n# test_eq(cfg.nbs_path, p/'nbs')\n\n\n\n\n\nCAMERA_SOURCE = 'AIRSIM'\n\nCAMERA_RESOLUTION = (640, 480)\nCAMERA_FPS = 30\nCAMERA_FLIP_METHOD = 0\nCAMERA_FLIP = False\nCAMERA_ROTATION = 0\nCAMERA_HFLIP = False\nCAMERA_VFLIP = False",
    "crumbs": [
      "Get Started",
      "API",
      "Parameters"
    ]
  },
  {
    "objectID": "api/params.html#configuring-uav",
    "href": "api/params.html#configuring-uav",
    "title": "Parameters",
    "section": "",
    "text": "_uav_home_dir = 'UAV' # subdirectory of xdg base dir\n_uav_cfg_name = 'settings.toml'    # todo use https://github.com/hukkin/tomli\n_uav_params_name = 'params.py'\n\n\n\n\nimport logging\n\n\nLOG_DIR = 'logs'\nLOGGING_LEVEL = logging.INFO\nLOGGING_NAME = 'uav_log'\n\n\n# test_eq(cfg.doc_path, p/'_docs')\n# test_eq(cfg.lib_path, p/'nbdev')\n# test_eq(cfg.nbs_path, p/'nbs')\n\n\n\n\n\nCAMERA_SOURCE = 'AIRSIM'\n\nCAMERA_RESOLUTION = (640, 480)\nCAMERA_FPS = 30\nCAMERA_FLIP_METHOD = 0\nCAMERA_FLIP = False\nCAMERA_ROTATION = 0\nCAMERA_HFLIP = False\nCAMERA_VFLIP = False",
    "crumbs": [
      "Get Started",
      "API",
      "Parameters"
    ]
  },
  {
    "objectID": "api/airsim.commands.html",
    "href": "api/airsim.commands.html",
    "title": "Airsim.Commands",
    "section": "",
    "text": "from fastcore.utils import *\n\nfrom UAV.airsim.client import AirSimClient\nimport UAV.airsim_python_client as airsim\nimport UAV.params as params\nimport time\nfrom UAV.utils.sim_linux import RunSim, is_process_running, find_and_terminate_process\nimport logging\nfrom UAV.airsim.commands import *\n\n\nlogging.basicConfig(format='%(asctime)-8s,%(msecs)-3d %(levelname)5s [name] [%(filename)10s:%(lineno)3d] %(message)s',\n                    datefmt='%H:%M:%S',\n                    level=params.LOGGING_LEVEL) \nlogger = logging.getLogger(params.LOGGING_NAME)\n\n\nfrom UAV.utils.display import *\nfrom UAV.utils.sim_linux import *\nfrom matplotlib import pyplot as plt\n\n\n\nstart_sim\n\n start_sim ()\n\nStart the Airsim simuator if it is not already running\n\n\n\nDroneCommands.arm\n\n DroneCommands.arm ()\n\nRun the drone on a path in the Airsim simulator. Creates a client and connects to the simulator.\n\n\n\nDroneCommands.takeoff\n\n DroneCommands.takeoff ()\n\nTakeoff to the takeoff height\n\n\n\nDroneCommands.do_NH_path\n\n DroneCommands.do_NH_path ()\n\nFly on a path in the Airsim simulator\n\n\n\nDroneCommands.rth\n\n DroneCommands.rth ()\n\n\n\n\nDroneCommands.land\n\n DroneCommands.land ()\n\n\n\n\nDroneCommands.disarm\n\n DroneCommands.disarm ()\n\nDisarm the drone and disconnect from the simulator\n\n\n\nDroneCommands.do_tasklist\n\n DroneCommands.do_tasklist ()\n\nRun a list of tasks in order\n\n\n\nDroneCommands.stop\n\n DroneCommands.stop ()\n\nstop the client by cancelling the last task and exiting the do_tasklist loop\n\n\nAn end to end example\nThe drone cammands are run in a separate process with the video loop running in the main process.\n\nRECORD_VIDEO = False\n\nimport threading\nfrom UAV.airsim.commands import DroneCommands\nfrom UAV.airsim.client import  AirSimClient\nimport UAV.airsim_python_client as airsim\nfrom UAV.utils.sim_linux import RunSim\nfrom UAV.utils.display import puttext, VideoWriter, ScrollingLog, ScrollingLogHandler\nfrom imutils import resize\nimport cv2\nimport logging\nimport time\n# logging.basicConfig(format=\n#                     '%(asctime)-8s,%(msecs)-3d %(levelname)5s [%(filename)10s:%(lineno)3d] %(message)s',\n#                     datefmt='%H:%M:%S',\n#                     level=logging.INFO)  \nimport UAV.params as params\nlogger = logging.getLogger(params.LOGGING_NAME) # Todo add this to params\nlogger.setLevel(params.LOGGING_LEVEL)\n# log = ScrollingLog(bg_color=(0,0,0))\nlog = ScrollingLog(position=(20,80), font_scale=1.5 , color=(0,0,255), thickness=1)\nhandler_log = ScrollingLogHandler(log, logger)\nlogger.info(f\"Hello World...\")\n\nrs = RunSim(\"AirSimNH\", settings=\"config/settings_high_res.json\")\n\nasc = AirSimClient()\ncmd = DroneCommands()\nt = threading.Thread(target=cmd.do_tasklist, daemon=True)\nt.start()\n\nframecounter = 1\ncam_num = 0\ncams = [\"high_res\", \"front_center\", \"front_right\", \"front_left\", \"bottom_center\", \"back_center\"]\n# with VideoWriter(\"images/airsim_test.mp4\", 5.0) as video:\nif RECORD_VIDEO:\n    video = VideoWriter(\"images/airsim_nav_test.mp4\", 5.0)\nelse:\n    video = None\n# with VideoWriter(\"images/airsim_nav_test.mp4\", 25.0) as video:\nif True:\n    while(True):\n        framecounter += 1\n        state = asc.getMultirotorState()\n        pos = state.kinematics_estimated.position\n        img = asc.get_image(cams[cam_num], rgb2bgr=False)\n        puttext(img, f\"Frame: {framecounter} Pos: {pos.x_val:.2f}, {pos.y_val:.2f}, {pos.z_val:.2f}\")\n    \n        img = resize(img, width=800)    \n        # log.update(f\"Frame: {framecounter} Pos: {pos.x_val:.2f}, {pos.y_val:.2f}, {pos.z_val:.2f}\")\n        if framecounter % 100 == 0:\n            print(f\"Frame: {framecounter} Pos: {pos.x_val:.2f}, {pos.y_val:.2f}, {pos.z_val:.2f}\")\n        log.draw(img)\n        cv2.imshow(\"Camera\", img)\n        if video is not None: video.add(img)\n        \n        # video.add(img_bgr)\n        k = cv2.waitKey(10)\n        if k == ord('q') or k == ord('Q'):\n            # logger.info(\"......cancelLastTask\")\n            asc.cancelLastTask()\n            # print(f\"Landed state:  {state.landed_state}\")\n            if state.landed_state == 0:\n                logger.info(\"Landed state = 0,  so quiting\")\n                break  \n        \n        if k == ord('c') or k == ord('C'):\n            cam_num += 1\n            if cam_num &gt;= len(cams):\n                cam_num = 0\n            # log.update(f\"Camera: {cams[cam_num]}\")\n            logger.info(f\"Camera: {cams[cam_num]}\")\n            \n        if k == 27:\n            cmd.stop()\n            time.sleep(1)\n            break\n            \n        # if framecounter &gt; 50:\n        #     break\n\ncmd.disarm()\nt.join(timeout=5)\ncv2.destroyAllWindows()\nrs.exit()\n\nif video is not None: \n    video.close()\n    video.show(width=500)\n\nINFO   | uav_log         | 13.731 | 2696093584.py: 23 | MainThread         | Hello World...\nINFO   | uav_log         | 16.754 | commands.py: 46 | Thread-6 (do_taskl | Arming the drone...\nINFO   | uav_log         | 16.755 | commands.py: 61 | Thread-6 (do_taskl | taking off...\nINFO   | uav_log         | 22.300 | commands.py: 82 | Thread-6 (do_taskl | flying on path...\nINFO   | uav_log         | 36.535 | commands.py: 93 | Thread-6 (do_taskl | returning home...\nINFO   | uav_log         | 39.553 | commands.py: 99 | Thread-6 (do_taskl | landing...\nINFO   | uav_log         | 41.276 | commands.py: 52 | Thread-6 (do_taskl | disarming...\nINFO   | uav_log         | 45.054 | 2696093584.py: 64 | MainThread         | Landed state = 0,  so quiting\nINFO   | uav_log         | 45.055 | commands.py: 52 | MainThread         | disarming...\n\n\nSettings file config/settings_high_res.json not found.\nStarting Airsim  ['/home/jn/Airsim/AirSimNH/LinuxNoEditor/AirSimNH/Binaries/Linux/AirSimNH', '-ResX=800', '-ResY=600', '-windowed']\nStarted Airsim AirSimNH\nConnected!\nClient Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\n\nWriting video to /home/jn/PycharmProjects/UAV/nbs/api/images/airsim_nav_test.mp4 at 5.0 fps.\nConnected!\nClient Ver:1 (Min Req: 1), Server Ver:1 (Min Req: 1)\nmake sure we are hovering at 5 meters...\nThis script is designed to fly on the streets of the Neighborhood environment\n            and assumes the unreal position of the drone is [160, -1500, 120].\nFrame: 100 Pos: 41.01, -0.00, -6.36\nFrame: 200 Pos: 126.92, -33.09, -10.31\nAirsim exited with rc = 143\nVideo: /home/jn/PycharmProjects/UAV/nbs/api/images/airsim_nav_test.mp4\n\n\nSorry, seems like your browser doesn't support HTML5 audio/video\n\n\n\n# rs.exit()",
    "crumbs": [
      "Get Started",
      "API",
      "Airsim.Commands"
    ]
  },
  {
    "objectID": "expt/detector.html",
    "href": "expt/detector.html",
    "title": "ball detector",
    "section": "",
    "text": "here …\n\n\nfrom PIL import Image\nfrom IPython.display import display\n\n\n# get current working dir\nimport os\n\ncurrent_working_dir = os.getcwd()\nprint(current_working_dir)\n\n\nimg = Image.open('../data/ball_0.jpg')\ndisplay(img)\n\n\nimport cv2\nimport numpy as np\n\nimg = cv2.imread('../data/ball_5.jpg')\ngray_img = (cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\na = gray_img.max()  \n_, thresh = cv2.threshold(gray_img, a/2+60, a, cv2.THRESH_BINARY)\ncv2.imshow(\"thresh\", thresh)\n\nkernel = np.ones((6,6),np.uint8)\nthresh0 = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n# thresh0 = cv2.morphologyEx(thresh0, cv2.MORPH_DILATE, kernel,iterations=3)\n\ncv2.imshow(\"thresh0\", thresh0)\ncontours, hierarchy = cv2.findContours(thresh0, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\ncontours = sorted(contours, key = cv2.contourArea, reverse = True)\nrects = []\nfor c in contours:\n    perimeter = cv2.arcLength(c,True)\n    x, y, w, h = cv2.boundingRect(c)\n    rects.append([x, y, w, h])\n    # if perimeter &gt; 60 and perimeter &lt; 150:\n    #     print(perimeter)\n    cv2.rectangle(img,(x,y), (x+w,y+h), (0,0,255), 2)\nprint(contours[0].shape)\nimage_copy = img.copy()\n# final_image = cv2.drawContours(image_copy, contours, contourIdx=-1, color=(0,255,0), thickness=2)\ncv2.imshow(\"image\", image_copy)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n(102, 1, 2)"
  },
  {
    "objectID": "expt/detector.html#ball-detector",
    "href": "expt/detector.html#ball-detector",
    "title": "ball detector",
    "section": "",
    "text": "here …\n\n\nfrom PIL import Image\nfrom IPython.display import display\n\n\n# get current working dir\nimport os\n\ncurrent_working_dir = os.getcwd()\nprint(current_working_dir)\n\n\nimg = Image.open('../data/ball_0.jpg')\ndisplay(img)\n\n\nimport cv2\nimport numpy as np\n\nimg = cv2.imread('../data/ball_5.jpg')\ngray_img = (cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\na = gray_img.max()  \n_, thresh = cv2.threshold(gray_img, a/2+60, a, cv2.THRESH_BINARY)\ncv2.imshow(\"thresh\", thresh)\n\nkernel = np.ones((6,6),np.uint8)\nthresh0 = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n# thresh0 = cv2.morphologyEx(thresh0, cv2.MORPH_DILATE, kernel,iterations=3)\n\ncv2.imshow(\"thresh0\", thresh0)\ncontours, hierarchy = cv2.findContours(thresh0, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\ncontours = sorted(contours, key = cv2.contourArea, reverse = True)\nrects = []\nfor c in contours:\n    perimeter = cv2.arcLength(c,True)\n    x, y, w, h = cv2.boundingRect(c)\n    rects.append([x, y, w, h])\n    # if perimeter &gt; 60 and perimeter &lt; 150:\n    #     print(perimeter)\n    cv2.rectangle(img,(x,y), (x+w,y+h), (0,0,255), 2)\nprint(contours[0].shape)\nimage_copy = img.copy()\n# final_image = cv2.drawContours(image_copy, contours, contourIdx=-1, color=(0,255,0), thickness=2)\ncv2.imshow(\"image\", image_copy)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n\n(102, 1, 2)"
  },
  {
    "objectID": "tutorials/mav_camera_walkthrough.html",
    "href": "tutorials/mav_camera_walkthrough.html",
    "title": "Mavlink Camera Walkthrough",
    "section": "",
    "text": "Here we create an entire mavlink connection with client at the GCS and server at the camera. The client and server are connected via a UDP connection or a radio modem serial connection The camera can be controlled via the client, and the video stream is sent from the server to the client. The client can also request camera information, storage information, etc from the server. The operatrion of the two cameras is controlled from a gui, which allows streaming , jpeg snapshots and recodring to be controlled \n\n\nimport asyncio\nimport platform\n\nfrom UAV.cameras.gst_cam import GSTCamera\nfrom UAV.logging import LogLevels\nfrom UAV.manager import Gui\nfrom UAV.mavlink import CameraClient, CameraServer, MAVCom, mavlink, GimbalServerViewsheen\n\nfrom UAV.utils import helpers\nfrom UAV.utils.general import boot_time_str, toml_load, config_dir\n\n\n# gst_utils.set_gst_debug_level(Gst.DebugLevel.FIXME)\n\nasync def main():\n    con1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB1\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyACM2\"\n    # logger.disabled = True\n    print(f\"{boot_time_str =}\")\n\n    # with GstContext(loglevel=LogLevels.CRITICAL):  # GST main loop in thread (to process messages and display errors)\n    \n    # run both drone nd GCS MAV connections on this computer\n    with MAVCom(con1, source_system=111, loglevel=LogLevels.CRITICAL) as GCS_client:  # This normally runs on GCS\n        with MAVCom(con2, source_system=222, loglevel=LogLevels.CRITICAL) as UAV_server:  # This normally runs on drone\n\n            # add GCS manager\n            gcs: CameraClient = GCS_client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11, loglevel=LogLevels.INFO))\n\n            server_config_dict = toml_load(config_dir() / f\"test_server_config.toml\")\n            print(server_config_dict)\n            # add 2 UAV cameras, This normally runs on drone\n            cam_0 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=LogLevels.DEBUG)\n            cam_1 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_1.toml\"), loglevel=LogLevels.DEBUG)\n\n            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_0, loglevel=LogLevels.INFO))\n            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA2, camera=cam_1, loglevel=LogLevels.INFO))\n\n            # Wait till heartbeat found\n            ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA, timeout=2)\n            print(f\"Camera Heartbeat {ret = }\")\n\n            # Camera manager GUI\n            gui = Gui(camera_client=gcs, gimbal_client=None)  # display GUI\n            t1 = asyncio.create_task(gui.find_cameras())   # find cameras from heartbeat info\n            t2 = asyncio.create_task(gui.run_gui())\n            \n            await asyncio.gather(t1, t2)\n            \n            # await asyncio.sleep(5)\n            \n            # try:\n            #     await asyncio.gather(t1, t3)\n            # except asyncio.CancelledError:\n            #     print(\"CancelledError\")\n            #     pass\n\n            cam_0.close()\n            cam_1.close()\n\n\n\n\nclient_config_dict = toml_load(config_dir() / f\"client_config.toml\")\nif platform.processor() != 'aarch64':\n    client_config_dict['camera_udp_decoder'] = 'h264'  # on pc override as h264\np = helpers.start_displays(client_config_dict, display_type='cv2')\nawait main()\np.terminate()\n\nFound config directory at: /home/john/PycharmProjects/UAV/config\ncv2_display udpsrc port={} ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nboot_time_str ='2024-01-24|10:21:20'\nFound config directory at: /home/john/PycharmProjects/UAV/config\n{'source_system': 222, 'camera_UDP_IP': '127.0.0.1', 'cam_0_UDP_port': 5000, 'cam_1_UDP_port': 5001, 'cam_10_UDP_port': 5010, 'usb_mount_command': 'udisksctl mount -b /dev/sda', 'image_save_path': '/media/{user}/jpgs', 'mavlink': {'source_system': 222, 'connection': '/dev/ttyUSB1'}}\nFound config directory at: /home/john/PycharmProjects/UAV/config\nJohn Doe                        \nFound config directory at: /home/john/PycharmProjects/UAV/config\nJohn Doe                        \nCamera Heartbeat ret = (222, 100)\nfind_gimbals exit_event =  &lt;asyncio.locks.Event object at 0x7f6fe1d06200 [unset]&gt;\n Found Camera 222/101\n Found Camera 222/100\nrun_gui exit\nfind_cameras exit True\n\n\nINFO |40.293| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nDEBUG|40.294| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \nDEBUG|40.295| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \nINFO |40.298| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5001 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nDEBUG|40.299| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \nDEBUG|40.299| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \nINFO |40.359| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO |40.361| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\nINFO |40.361| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\nINFO |40.362| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_0_UDP_port = 5000\nINFO |40.374| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_0 \nDEBUG|40.375| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|40.375| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |40.377| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\nDEBUG|40.377| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|40.378| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |40.379| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\nDEBUG|40.479| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |40.480| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\nINFO |40.482| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\nINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\nINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_1_UDP_port = 5001\nINFO |40.497| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Left\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_1 \nDEBUG|40.498| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|40.498| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |40.500| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_1 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5001 sync=true\nDEBUG|40.500| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|40.501| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |40.502| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5001\nDEBUG|40.602| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |40.603| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5001\nINFO |40.604| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nINFO |40.605| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 101, self.mav_type = 30, self.source_system = 222\nWARNI|40.606| root            | asyncio_gu:271 | MainThread | MainProces | Gui auto is not callable\nWARNI|40.607| root            | asyncio_gu:273 | MainThread | MainProces | Gui reset is not callable\nWARNI|40.607| root            | asyncio_gu:275 | MainThread | MainProces | Gui pause is not callable\nDEBUG|43.667| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\nDEBUG|43.669| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\nDEBUG|43.771| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\nDEBUG|43.814| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\nINFO |43.815| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |43.817| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nDEBUG|43.987| pygst.GstStream | gst_tools.:967 | Thread-22  | MainProces | Sending EOS event, to trigger shutdown of pipeline\nINFO |43.989| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |43.990| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nDEBUG|43.991| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\nDEBUG|43.992| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\nDEBUG|44.094| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\nDEBUG|44.110| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\nINFO |44.111| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.112| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nDEBUG|44.309| pygst.GstStream | gst_tools.:967 | Thread-23  | MainProces | Sending EOS event, to trigger shutdown of pipeline\nINFO |44.311| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.312| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.363| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.364| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nINFO |44.465| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.466| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.467| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |44.469| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.470| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nINFO |44.571| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.573| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.574| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |44.611| mavcom.CameraCl | basecompon:417 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Camera Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/mav_camera_walkthrough.html#simple-camera-manager",
    "href": "tutorials/mav_camera_walkthrough.html#simple-camera-manager",
    "title": "Mavlink Camera Walkthrough",
    "section": "",
    "text": "Here we create an entire mavlink connection with client at the GCS and server at the camera. The client and server are connected via a UDP connection or a radio modem serial connection The camera can be controlled via the client, and the video stream is sent from the server to the client. The client can also request camera information, storage information, etc from the server. The operatrion of the two cameras is controlled from a gui, which allows streaming , jpeg snapshots and recodring to be controlled \n\n\nimport asyncio\nimport platform\n\nfrom UAV.cameras.gst_cam import GSTCamera\nfrom UAV.logging import LogLevels\nfrom UAV.manager import Gui\nfrom UAV.mavlink import CameraClient, CameraServer, MAVCom, mavlink, GimbalServerViewsheen\n\nfrom UAV.utils import helpers\nfrom UAV.utils.general import boot_time_str, toml_load, config_dir\n\n\n# gst_utils.set_gst_debug_level(Gst.DebugLevel.FIXME)\n\nasync def main():\n    con1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB1\"\n    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyACM2\"\n    # logger.disabled = True\n    print(f\"{boot_time_str =}\")\n\n    # with GstContext(loglevel=LogLevels.CRITICAL):  # GST main loop in thread (to process messages and display errors)\n    \n    # run both drone nd GCS MAV connections on this computer\n    with MAVCom(con1, source_system=111, loglevel=LogLevels.CRITICAL) as GCS_client:  # This normally runs on GCS\n        with MAVCom(con2, source_system=222, loglevel=LogLevels.CRITICAL) as UAV_server:  # This normally runs on drone\n\n            # add GCS manager\n            gcs: CameraClient = GCS_client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11, loglevel=LogLevels.INFO))\n\n            server_config_dict = toml_load(config_dir() / f\"test_server_config.toml\")\n            print(server_config_dict)\n            # add 2 UAV cameras, This normally runs on drone\n            cam_0 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=LogLevels.DEBUG)\n            cam_1 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_1.toml\"), loglevel=LogLevels.DEBUG)\n\n            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_0, loglevel=LogLevels.INFO))\n            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA2, camera=cam_1, loglevel=LogLevels.INFO))\n\n            # Wait till heartbeat found\n            ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA, timeout=2)\n            print(f\"Camera Heartbeat {ret = }\")\n\n            # Camera manager GUI\n            gui = Gui(camera_client=gcs, gimbal_client=None)  # display GUI\n            t1 = asyncio.create_task(gui.find_cameras())   # find cameras from heartbeat info\n            t2 = asyncio.create_task(gui.run_gui())\n            \n            await asyncio.gather(t1, t2)\n            \n            # await asyncio.sleep(5)\n            \n            # try:\n            #     await asyncio.gather(t1, t3)\n            # except asyncio.CancelledError:\n            #     print(\"CancelledError\")\n            #     pass\n\n            cam_0.close()\n            cam_1.close()\n\n\n\n\nclient_config_dict = toml_load(config_dir() / f\"client_config.toml\")\nif platform.processor() != 'aarch64':\n    client_config_dict['camera_udp_decoder'] = 'h264'  # on pc override as h264\np = helpers.start_displays(client_config_dict, display_type='cv2')\nawait main()\np.terminate()\n\nFound config directory at: /home/john/PycharmProjects/UAV/config\ncv2_display udpsrc port={} ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nboot_time_str ='2024-01-24|10:21:20'\nFound config directory at: /home/john/PycharmProjects/UAV/config\n{'source_system': 222, 'camera_UDP_IP': '127.0.0.1', 'cam_0_UDP_port': 5000, 'cam_1_UDP_port': 5001, 'cam_10_UDP_port': 5010, 'usb_mount_command': 'udisksctl mount -b /dev/sda', 'image_save_path': '/media/{user}/jpgs', 'mavlink': {'source_system': 222, 'connection': '/dev/ttyUSB1'}}\nFound config directory at: /home/john/PycharmProjects/UAV/config\nJohn Doe                        \nFound config directory at: /home/john/PycharmProjects/UAV/config\nJohn Doe                        \nCamera Heartbeat ret = (222, 100)\nfind_gimbals exit_event =  &lt;asyncio.locks.Event object at 0x7f6fe1d06200 [unset]&gt;\n Found Camera 222/101\n Found Camera 222/100\nrun_gui exit\nfind_cameras exit True\n\n\nINFO |40.293| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nDEBUG|40.294| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \nDEBUG|40.295| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \nINFO |40.298| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5001 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \nDEBUG|40.299| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \nDEBUG|40.299| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \nINFO |40.359| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\nINFO |40.361| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\nINFO |40.361| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\nINFO |40.362| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_0_UDP_port = 5000\nINFO |40.374| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_0 \nDEBUG|40.375| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|40.375| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |40.377| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\nDEBUG|40.377| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|40.378| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |40.379| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\nDEBUG|40.479| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |40.480| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\nINFO |40.482| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\nINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\nINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_1_UDP_port = 5001\nINFO |40.497| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Left\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_1 \nDEBUG|40.498| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|40.498| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |40.500| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_1 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5001 sync=true\nDEBUG|40.500| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|40.501| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |40.502| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5001\nDEBUG|40.602| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |40.603| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5001\nINFO |40.604| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\nINFO |40.605| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 101, self.mav_type = 30, self.source_system = 222\nWARNI|40.606| root            | asyncio_gu:271 | MainThread | MainProces | Gui auto is not callable\nWARNI|40.607| root            | asyncio_gu:273 | MainThread | MainProces | Gui reset is not callable\nWARNI|40.607| root            | asyncio_gu:275 | MainThread | MainProces | Gui pause is not callable\nDEBUG|43.667| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\nDEBUG|43.669| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\nDEBUG|43.771| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\nDEBUG|43.814| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\nINFO |43.815| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |43.817| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nDEBUG|43.987| pygst.GstStream | gst_tools.:967 | Thread-22  | MainProces | Sending EOS event, to trigger shutdown of pipeline\nINFO |43.989| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |43.990| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nDEBUG|43.991| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\nDEBUG|43.992| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\nDEBUG|44.094| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\nDEBUG|44.110| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\nINFO |44.111| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.112| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nDEBUG|44.309| pygst.GstStream | gst_tools.:967 | Thread-23  | MainProces | Sending EOS event, to trigger shutdown of pipeline\nINFO |44.311| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.312| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.363| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.364| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nINFO |44.465| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.466| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.467| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |44.469| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\nINFO |44.470| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\nINFO |44.571| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\nINFO |44.573| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \nINFO |44.574| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\nINFO |44.611| mavcom.CameraCl | basecompon:417 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Camera Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/mav_camera_walkthrough.html#more-detail",
    "href": "tutorials/mav_camera_walkthrough.html#more-detail",
    "title": "Mavlink Camera Walkthrough",
    "section": "More Detail",
    "text": "More Detail\n\nCreate a GST Camera\nCreate physical camera object, as either a CV2Camera or GSTCamera The toml file contains the camera parameters, such as resolution, framerate, etc and also the gstreamer pipeline command to create the video streams.\n\nserver_config_dict = toml_load(config_dir() / f\"test_server_config.toml\")\ncam_0 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=LogLevels.DEBUG)\n\nINFO |48.505| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\nINFO |48.505| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\nINFO |48.506| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_0_UDP_port = 5000\nINFO |48.529| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_0 \nDEBUG|48.529| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \nDEBUG|48.530| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \nINFO |48.532| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\nDEBUG|48.532| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \nDEBUG|48.534| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \nINFO |48.535| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\nDEBUG|48.635| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\nINFO |48.636| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\n\n\nFound config directory at: /home/john/PycharmProjects/UAV/config\nFound config directory at: /home/john/PycharmProjects/UAV/config\nJohn Doe                        \n\n\n\n\nCamera Configuration toml file printout\ncam_name = 'cam_0'\n\n[camera_info]\nvendor_name = \"John Doe                   \"\nmodel_name = \"Fake Camera                  \"\nfirmware_version = 1\nfocal_length = 8.0\nsensor_size_h = 6.0\nsensor_size_v = 4.0\nresolution_h = 1920\nresolution_v = 1080\nlens_id = 0\nflags = 0\ncam_definition_version = 1\ncam_definition_uri = \"http://example.com/camera_definition.xml\"\n\n[camera_position]\nx = 0.0\ny = 0.0\nz = 0.0\nroll = 0.0\npitch = 0.0\nyaw = 0.0\n\n[gstreamer_video_src]\nfps = 30   # Frames per second\nwidth = 800\nheight = 600\nloglevel = 'DEBUG'   # todo add loglevel to all pipelines and to gst_utils\n\npipeline = [\n    'videotestsrc pattern=ball is-live=true ! timeoverlay',\n    'textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true',\n    'capsfilter caps=video/x-raw,format=RGB,width={width},height={height},framerate={fps}/1',\n    'tee name=t',\n\n    \"t.\",\n    'queue', 'videoscale ', 'capsfilter caps=video/x-raw,format=RGB,width=400,height=300',\n    'videoconvert ! autovideosink',\n\n#    \"t.\",\n#    'queue leaky=2 ! intervideosink channel=channel_0  sync=false',\n#\n#    \"t.\",\n#    'queue leaky=2 ! intervideosink channel={cam_name}  sync=false',\n\n    \"t.\",\n    'interpipesink name={cam_name} ',\n]\n\n[gstreamer_udpsink]\nfps=2\nhost = '*camera_UDP_IP*'     # overwrite with server_config.toml\nport = '*cam_0_UDP_port*'    # overwrite with server_config.toml\npipeline = [\n\n    'interpipesrc listen-to={cam_name} is-live=true allow-renegotiation=true format=time',\n#    'queue max-size-buffers=1 leaky=downstream',\n    'valve name=myvalve drop=False ',\n    'queue',\n    'videorate drop-only=true skip-to-first=true ! video/x-raw,framerate={fps}/1',\n    'videoconvert',\n     'x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast',\n#    'x264enc tune=zerolatency',\n    'rtph264pay ! udpsink host={host} port={port} sync=true',\n    ]\n\n[gstreamer_jpg_filesink]\nfps = 10   # Frames per second * 10\nquality = 85\nfilenames = '%03d.jpg'\nindex = 0\n\npipeline = [\n    'interpipesrc listen-to={cam_name} is-live=false allow-renegotiation=true format=time',\n    'queue',\n    'videorate drop-only=true skip-to-first=true ! video/x-raw,framerate={fps}/10',\n    'videoconvert ! video/x-raw, format=I420',\n    'jpegenc quality={quality}',  # Quality of encoding, default is 85\n    'multifilesink location={save_path}/{cam_name}/{filenames} max-files=10 index={index}',\n    ]\n\n\nMAVlink connections\nCreate the client mavlink connection, this is mounted on the GCS\n\n# for the client, we use the udpin connection, you can use serial as an option i.e \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\nclient = MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.INFO)\n\nINFO |48.758| mavcom.MAVCom   | mavcom.py :386 | Thread-25  | MainProces | MAVLink Mav2: True, source_system: 111\n\n\nCreate the server mavlink connection, this is mounted on the UAV companion computer\n\n# for the server, we use the udpout connection, you can use serial as an option  \"/dev/ttyUSB0\"\nserver = MAVCom(\"udpout:localhost:14445\", source_system=222)\n\nINFO |48.871| mavcom.MAVCom   | mavcom.py :386 | Thread-26  | MainProces | MAVLink Mav2: True, source_system: 222\n\n\n\n\nAdd Camera\nAdd the camera client to the client mavlink connection\n\ncam = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))\n\nINFO |48.895| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\n\n\nAdd the camera server to the server mavlink connection\n\nserver.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_0))\n\nINFO |48.908| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\n\n\n&lt;CameraServer&gt;\n\n\nWait for the heartbeat from the camera server\n\nasync def doit():\n    ret = await cam.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n    print(f\"Heartbeat received {ret = }\")\nawait doit()\n\nHeartbeat received ret = (222, 100)\n\n\nSet the target system and component for the camera client and request camera information, storage information, camera capture status, and camera settings\n\nasync def doit():\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n    print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\nawait doit()\n\nDEBUG|48.934| uav.GSTCamera   | gst_cam.py:273 | Thread-30  | MainProces | self.mav.srcSystem = 222 self.mav.srcComponent = 100\nDEBUG|48.935| uav.GSTCamera   | gst_cam.py:274 | Thread-30  | MainProces | camera_information_send self.camera_info = {'vendor_name': [74, 111, 104, 110, 32, 68, 111, 101, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], 'model_name': [70, 97, 107, 101, 32, 67, 97, 109, 101, 114, 97, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], 'firmware_version': 1, 'focal_length': 8.0, 'sensor_size_h': 6.0, 'sensor_size_v': 4.0, 'resolution_h': 1920, 'resolution_v': 1080, 'lens_id': 0, 'flags': 0, 'cam_definition_version': 1, 'cam_definition_uri': 'http://example.com/camera_definition.xml'} self.mav = &lt;pymavlink.dialects.v20.ardupilotmega.MAVLink object&gt;\n\n\n1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 220300, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 220401, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 0.0, available_capacity : 100000000.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 220502, image_status : 0, video_status : 0, image_interval : 0.0, recording_time_ms : 0, available_capacity : 0.0, image_count : 0}\n4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 220604, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\n\n\n\n\nStart an image capture seqeunce,\nand display the images as they arrive\n\n# cam.image_start_capture(interval=0.1, count=10)\n# while cam_gst_1.capture_thread.is_alive():\n#     if cam_gst_1.last_image is not None:\n#         cv2.imshow('gst_src', cam_gst_1.last_image)\n#         cam_gst_1.last_image = None\n#     cv2.waitKey(10)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Mavlink Camera Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with UAV’s features.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nAirsim Walkthrough\n\n\nDocumentation for using Microsoft Airsim in a Jupyter notebook\n\n\n\n\nMavlink Camera Walkthrough\n\n\nDocumentation\n\n\n\n\ntemplate01\n\n\nbla bla bla\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "Tutorials"
    ]
  }
]